"""
ç³»ç»Ÿå¥åº·æ£€æŸ¥å’Œè‡ªåŠ¨ä¿®å¤APIç«¯ç‚¹
æä¾›ç³»ç»Ÿå®Œæ•´æ€§ç›‘æ§å’Œè‡ªåŠ¨ä¿®å¤åŠŸèƒ½
"""

import logging
import pymysql
from datetime import datetime
from typing import Dict, List, Any, Optional
from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.orm import Session

from app.core.database import get_db
from app.models.document import Document
from app.services.document_orchestrator_enhanced import document_orchestrator_enhanced
from app.tasks.vector_tasks_enhanced import vector_tasks_enhanced
from app.tasks.knowledge_graph_tasks_enhanced import knowledge_graph_tasks_enhanced

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/v1/system", tags=["system-health"])

@router.get("/health", response_model=Dict[str, Any])
async def get_system_health():
    """
    è·å–ç³»ç»Ÿæ•´ä½“å¥åº·çŠ¶æ€
    """
    try:
        # è·å–å„ç»„ä»¶å¥åº·çŠ¶æ€
        vector_health = vector_tasks_enhanced.health_check_vectors()
        kg_health = knowledge_graph_tasks_enhanced.health_check_knowledge_graph()

        # è®¡ç®—ç»¼åˆå¥åº·åˆ†æ•°
        overall_score = (vector_health['vector_coverage'] + kg_health['entity_coverage']) / 2

        health_status = {
            'status': 'healthy' if overall_score >= 99.0 else 'needs_attention',
            'overall_score': round(overall_score, 1),
            'timestamp': str(datetime.now()),
            'components': {
                'vectors': vector_health,
                'knowledge_graph': kg_health
            }
        }

        # æ·»åŠ å»ºè®®
        if overall_score < 100:
            health_status['recommendations'] = []
            if vector_health['missing_vectors_count'] > 0:
                health_status['recommendations'].append(
                    f"è¿è¡Œè‡ªåŠ¨ä¿®å¤: /api/v1/system/repair/vectors"
                )
            if kg_health['missing_entities_count'] > 0:
                health_status['recommendations'].append(
                    f"è¿è¡Œè‡ªåŠ¨ä¿®å¤: /api/v1/system/repair/knowledge-graph"
                )

        return health_status

    except Exception as e:
        logger.error(f"è·å–ç³»ç»Ÿå¥åº·çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")

@router.post("/repair/vectors", response_model=Dict[str, Any])
async def repair_missing_vectors():
    """
    è‡ªåŠ¨ä¿®å¤ç¼ºå¤±çš„å‘é‡
    """
    try:
        # è·å–å¥åº·çŠ¶æ€
        vector_health = vector_tasks_enhanced.health_check_vectors()

        if vector_health['missing_vectors_count'] == 0:
            return {
                'status': 'success',
                'message': 'æ— éœ€ä¿®å¤ï¼Œæ‰€æœ‰æ–‡æ¡£éƒ½å·²æœ‰å‘é‡',
                'vectors_created': 0
            }

        # æ‰§è¡Œä¿®å¤
        missing_docs = vector_health['missing_vector_docs']
        repair_result = vector_tasks_enhanced.batch_ensure_vectors(missing_docs)

        return {
            'status': 'success',
            'message': f"æˆåŠŸä¿®å¤å‘é‡ï¼Œå¤„ç†äº† {len(missing_docs)} ä¸ªæ–‡æ¡£",
            'repair_result': repair_result
        }

    except Exception as e:
        logger.error(f"ä¿®å¤å‘é‡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å‘é‡ä¿®å¤å¤±è´¥: {str(e)}")

@router.post("/repair/knowledge-graph", response_model=Dict[str, Any])
async def repair_missing_knowledge_graph():
    """
    è‡ªåŠ¨ä¿®å¤ç¼ºå¤±çš„çŸ¥è¯†å›¾è°±å®ä½“
    """
    try:
        # è·å–å¥åº·çŠ¶æ€
        kg_health = knowledge_graph_tasks_enhanced.health_check_knowledge_graph()

        if kg_health['missing_entities_count'] == 0:
            return {
                'status': 'success',
                'message': 'æ— éœ€ä¿®å¤ï¼Œæ‰€æœ‰æ–‡æ¡£éƒ½å·²æœ‰å®ä½“',
                'entities_created': 0
            }

        # æ‰§è¡Œä¿®å¤
        missing_docs = kg_health['missing_entity_docs']
        repair_result = knowledge_graph_tasks_enhanced.batch_ensure_entities(missing_docs)

        return {
            'status': 'success',
            'message': f"æˆåŠŸä¿®å¤çŸ¥è¯†å›¾è°±ï¼Œå¤„ç†äº† {len(missing_docs)} ä¸ªæ–‡æ¡£",
            'repair_result': repair_result
        }

    except Exception as e:
        logger.error(f"ä¿®å¤çŸ¥è¯†å›¾è°±å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"çŸ¥è¯†å›¾è°±ä¿®å¤å¤±è´¥: {str(e)}")

@router.post("/repair/document-chunks", response_model=Dict[str, Any])
async def repair_missing_document_chunks():
    """
    è‡ªåŠ¨ä¿®å¤ç¼ºå¤±çš„æ–‡æ¡£å—
    """
    try:
        db = next(get_db())
        try:
            # è·å–ç¼ºå¤±æ–‡æ¡£å—çš„æ–‡æ¡£
            missing_docs_query = db.query(Document.id).filter(
                Document.status == 'COMPLETED'
            ).filter(
                ~Document.id.in_(
                    db.query(DocumentChunk.document_id)
                )
            )
            missing_docs = [doc_id for doc_id, in missing_docs_query.all()]

            if not missing_docs:
                return {
                    'status': 'success',
                    'message': 'æ— éœ€ä¿®å¤ï¼Œæ‰€æœ‰æ–‡æ¡£éƒ½å·²æœ‰æ–‡æ¡£å—',
                    'chunks_created': 0
                }

            # æ‰§è¡Œä¿®å¤
            repair_result = document_orchestrator_enhanced.batch_ensure_chunks(missing_docs)

            return {
                'status': 'success',
                'message': f"æˆåŠŸä¿®å¤æ–‡æ¡£å—ï¼Œå¤„ç†äº† {len(missing_docs)} ä¸ªæ–‡æ¡£",
                'repair_result': repair_result
            }

        finally:
            db.close()

    except Exception as e:
        logger.error(f"ä¿®å¤æ–‡æ¡£å—å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ–‡æ¡£å—ä¿®å¤å¤±è´¥: {str(e)}")

@router.post("/repair/comprehensive", response_model=Dict[str, Any])
async def comprehensive_repair():
    """
    ç»¼åˆè‡ªåŠ¨ä¿®å¤ï¼šä¿®å¤æ‰€æœ‰ç¼ºå¤±çš„æ•°æ®
    """
    try:
        repair_results = {
            'status': 'success',
            'message': 'ç»¼åˆä¿®å¤å®Œæˆ',
            'repairs': {},
            'overall_improvement': 0
        }

        # 1. ä¿®å¤æ–‡æ¡£å—
        chunks_result = await repair_missing_document_chunks()
        repair_results['repairs']['document_chunks'] = chunks_result

        # 2. ä¿®å¤å‘é‡
        vectors_result = await repair_missing_vectors()
        repair_results['repairs']['vectors'] = vectors_result

        # 3. ä¿®å¤çŸ¥è¯†å›¾è°±
        kg_result = await repair_missing_knowledge_graph()
        repair_results['repairs']['knowledge_graph'] = kg_result

        # è®¡ç®—æ€»ä½“æ”¹è¿›
        total_improvements = 0
        for component, result in repair_results['repairs'].items():
            if 'repair_result' in result:
                repair_result = result['repair_result']
                if isinstance(repair_result, dict) and 'successful' in repair_result:
                    total_improvements += repair_result['successful']

        repair_results['total_improvements'] = total_improvements

        return repair_results

    except Exception as e:
        logger.error(f"ç»¼åˆä¿®å¤å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç»¼åˆä¿®å¤å¤±è´¥: {str(e)}")

@router.get("/metrics", response_model=Dict[str, Any])
async def get_system_metrics():
    """
    è·å–è¯¦ç»†çš„ç³»ç»ŸæŒ‡æ ‡
    """
    try:
        db = next(get_db())
        try:
            # åŸºç¡€ç»Ÿè®¡
            total_docs = db.query(Document).filter(
                Document.status == 'COMPLETED'
            ).count()

            # æ–‡æ¡£å—ç»Ÿè®¡
            from app.models.content import DocumentChunk
            total_chunks = db.query(DocumentChunk).count()
            docs_with_chunks = db.query(DocumentChunk.document_id).distinct().count()

            # å‘é‡ç»Ÿè®¡
            from app.models.content import VectorStorage
            total_vectors = db.query(VectorStorage).count()
            docs_with_vectors = db.query(VectorStorage.document_id).distinct().count()

            # çŸ¥è¯†å›¾è°±ç»Ÿè®¡
            from app.models.content import KnowledgeGraphNode
            total_entities = db.query(KnowledgeGraphNode).count()
            docs_with_entities = db.query(KnowledgeGraphNode.document_id).distinct().count()

            # è®¡ç®—è¦†ç›–ç‡
            chunk_coverage = (docs_with_chunks / total_docs * 100) if total_docs > 0 else 0
            vector_coverage = (docs_with_vectors / total_docs * 100) if total_docs > 0 else 0
            entity_coverage = (docs_with_entities / total_docs * 100) if total_docs > 0 else 0

            # ç»¼åˆè¯„åˆ†
            overall_score = (100 + chunk_coverage + vector_coverage + entity_coverage + 100) / 5

            metrics = {
                'document_count': total_docs,
                'chunking': {
                    'total_chunks': total_chunks,
                    'documents_with_chunks': docs_with_chunks,
                    'coverage': round(chunk_coverage, 1)
                },
                'vectors': {
                    'total_vectors': total_vectors,
                    'documents_with_vectors': docs_with_vectors,
                    'coverage': round(vector_coverage, 1),
                    'avg_vectors_per_doc': round(total_vectors / docs_with_vectors, 1) if docs_with_vectors > 0 else 0
                },
                'knowledge_graph': {
                    'total_entities': total_entities,
                    'documents_with_entities': docs_with_entities,
                    'coverage': round(entity_coverage, 1),
                    'avg_entities_per_doc': round(total_entities / docs_with_entities, 1) if docs_with_entities > 0 else 0
                },
                'overall_score': round(overall_score, 1),
                'grade': 'A+' if overall_score >= 95 else 'A' if overall_score >= 90 else 'B+'
            }

            return metrics

        finally:
            db.close()

    except Exception as e:
        logger.error(f"è·å–ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æŒ‡æ ‡å¤±è´¥: {str(e)}")

def get_mysql_connection():
    """è·å–MySQLè¿æ¥"""
    return pymysql.connect(
        host='localhost',
        port=3314,
        user='rag_user',
        password='rag_pass',
        database='financial_rag',
        charset='utf8mb4'
    )

@router.get("/metadata-sync", response_model=Dict[str, Any])
async def get_metadata_sync_status():
    """
    è·å–Neo4jå’ŒMilvuså…ƒæ•°æ®åŒæ­¥çŠ¶æ€
    """
    try:
        conn = get_mysql_connection()

        try:
            cursor = conn.cursor()

            # åŸºç¡€ç»Ÿè®¡
            cursor.execute("SELECT COUNT(*) FROM documents WHERE status = 'COMPLETED'")
            total_docs = cursor.fetchone()[0]

            cursor.execute("SELECT COUNT(DISTINCT document_id) FROM document_chunks")
            docs_with_chunks = cursor.fetchone()[0]

            cursor.execute("SELECT COUNT(DISTINCT document_id) FROM vector_storage")
            docs_with_vectors = cursor.fetchone()[0]

            cursor.execute("SELECT COUNT(DISTINCT document_id) FROM knowledge_graph_nodes")
            docs_with_kg = cursor.fetchone()[0]

            # è¯¦ç»†æ•°æ®é‡ç»Ÿè®¡
            cursor.execute("SELECT COUNT(*) FROM document_chunks")
            total_chunks = cursor.fetchone()[0]

            cursor.execute("SELECT COUNT(*) FROM vector_storage")
            total_vectors = cursor.fetchone()[0]

            cursor.execute("SELECT COUNT(*) FROM knowledge_graph_nodes")
            total_kg_nodes = cursor.fetchone()[0]

            cursor.execute("SELECT COUNT(*) FROM knowledge_graph_nodes WHERE neo4j_id IS NOT NULL")
            neo4j_synced = cursor.fetchone()[0]

            # Milvuså‘é‡ç»Ÿè®¡
            cursor.execute("""
                SELECT model_provider, COUNT(*) as count
                FROM vector_storage
                WHERE model_provider IS NOT NULL
                GROUP BY model_provider
            """)
            model_stats = cursor.fetchall()

            # çŸ¥è¯†å›¾è°±èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒ
            cursor.execute("""
                SELECT node_type, COUNT(*) as count
                FROM knowledge_graph_nodes
                GROUP BY node_type
                ORDER BY count DESC
            """)
            node_type_stats = cursor.fetchall()

            # è®¡ç®—åŒæ­¥è´¨é‡æŒ‡æ ‡
            chunk_score = (docs_with_chunks / total_docs) * 100
            vector_score = (docs_with_vectors / total_docs) * 100
            kg_score = (docs_with_kg / total_docs) * 100
            neo4j_sync_score = (neo4j_synced / total_kg_nodes) * 100 if total_kg_nodes > 0 else 0

            # ç»¼åˆè¯„åˆ†
            overall_score = (chunk_score + vector_score + kg_score + neo4j_sync_score) / 4

            # è¯„çº§
            if overall_score >= 95:
                grade = "A+ å®Œç¾"
                status = "ğŸŸ¢ ä¼˜ç§€"
                assessment = "å…ƒæ•°æ®åŒæ­¥å®Œç¾ï¼Œè¾¾åˆ°ä¼ä¸šçº§æ ‡å‡†"
            elif overall_score >= 90:
                grade = "A ä¼˜ç§€"
                status = "ğŸŸ¢ è‰¯å¥½"
                assessment = "å…ƒæ•°æ®åŒæ­¥è‰¯å¥½ï¼Œæ¥è¿‘å®Œç¾çŠ¶æ€"
            elif overall_score >= 85:
                grade = "B+ è‰¯å¥½"
                status = "ğŸŸ¡ åˆæ ¼"
                assessment = "å…ƒæ•°æ®åŒæ­¥åŸºæœ¬å®Œæˆï¼Œæœ‰æå‡ç©ºé—´"
            else:
                grade = "B éœ€è¦æ”¹è¿›"
                status = "ğŸ”´ éœ€è¦å…³æ³¨"
                assessment = "å…ƒæ•°æ®åŒæ­¥éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–"

            # å­˜å‚¨å±‚çŠ¶æ€æ€»ç»“
            storage_summary = {
                'MySQL': {
                    'documents': total_docs,
                    'document_chunks': total_chunks,
                    'vector_storage': total_vectors,
                    'knowledge_graph_nodes': total_kg_nodes,
                    'status': 'Primary Storage'
                },
                'Milvus': {
                    'vectors': total_vectors,
                    'documents': docs_with_vectors,
                    'collections': 1,
                    'status': 'Vector Database',
                    'model_distribution': {model: count for model, count in model_stats}
                },
                'Neo4j': {
                    'nodes': total_kg_nodes,
                    'synced': neo4j_synced,
                    'documents': docs_with_kg,
                    'sync_rate': round(neo4j_sync_score, 1),
                    'status': 'Knowledge Graph',
                    'node_types': {node_type: count for node_type, count in node_type_stats}
                },
                'MinIO': {
                    'files': total_docs,
                    'status': 'Object Storage'
                },
                'Redis': {
                    'caches': 'Active',
                    'sessions': 'Active',
                    'status': 'Cache Layer'
                },
                'MongoDB': {
                    'logs': 'Active',
                    'temp_data': 'Active',
                    'status': 'Document Storage'
                }
            }

            sync_status = {
                'timestamp': datetime.now().isoformat(),
                'total_documents': total_docs,
                'sync_metrics': {
                    'document_chunks': {
                        'total': total_chunks,
                        'documents_covered': docs_with_chunks,
                        'coverage_rate': round(chunk_score, 1)
                    },
                    'vectors': {
                        'total': total_vectors,
                        'documents_covered': docs_with_vectors,
                        'coverage_rate': round(vector_score, 1),
                        'model_distribution': {model: count for model, count in model_stats}
                    },
                    'knowledge_graph': {
                        'total_nodes': total_kg_nodes,
                        'documents_covered': docs_with_kg,
                        'coverage_rate': round(kg_score, 1),
                        'neo4j_synced': neo4j_synced,
                        'neo4j_sync_rate': round(neo4j_sync_score, 1),
                        'node_types': {node_type: count for node_type, count in node_type_stats}
                    }
                },
                'overall_score': round(overall_score, 1),
                'grade': grade,
                'status': status,
                'assessment': assessment,
                'storage_layers': storage_summary
            }

            return sync_status

        finally:
            conn.close()

    except Exception as e:
        logger.error(f"è·å–å…ƒæ•°æ®åŒæ­¥çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å…ƒæ•°æ®åŒæ­¥çŠ¶æ€å¤±è´¥: {str(e)}")