"""
æ ¸å¿ƒæœåŠ¡æ•´åˆå™¨ - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰åˆ†æ•£çš„æœåŠ¡åŠŸèƒ½
æ•´åˆæ–‡æ¡£å¤„ç†ã€å¤šæ¨¡æ€åˆ†æã€åµŒå…¥ç”Ÿæˆã€çŸ¥è¯†å›¾è°±ç­‰æ ¸å¿ƒåŠŸèƒ½
"""

import logging
import asyncio
from typing import Dict, Any, List, Optional, Union
from dataclasses import dataclass
from datetime import datetime
import json

# æ ¸å¿ƒæœåŠ¡å¯¼å…¥
from app.services.real_qwen_service import RealQwenService, RealQwenConfig
from app.services.qwen_embedding_service import QwenEmbeddingService
from app.services.minio_service import MinIOService
from app.services.milvus_service import MilvusService
from app.services.neo4j_service import Neo4jService
from app.services.document_deduplication import DocumentDeduplicationService

logger = logging.getLogger(__name__)


@dataclass
class ServiceConfig:
    """ç»Ÿä¸€æœåŠ¡é…ç½®"""
    qwen_api_key: str = "sk-5233a3a4b1a24426b6846a432794bbe2"
    qwen_base_url: str = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    enable_multimodal: bool = True
    enable_entity_extraction: bool = True
    enable_knowledge_graph: bool = True
    max_workers: int = 4
    timeout: int = 120


class CoreServiceIntegrator:
    """
    æ ¸å¿ƒæœåŠ¡æ•´åˆå™¨
    ç»Ÿä¸€ç®¡ç†æ–‡æ¡£å¤„ç†ã€å¤šæ¨¡æ€åˆ†æã€åµŒå…¥ç”Ÿæˆç­‰åŠŸèƒ½
    é¿å…ä»£ç åˆ†æ•£ï¼Œæä¾›ç»Ÿä¸€çš„æœåŠ¡å…¥å£
    """

    def __init__(self, config: Optional[ServiceConfig] = None):
        self.config = config or ServiceConfig()
        self._services = {}
        self._initialized = False

    async def initialize(self):
        """å¼‚æ­¥åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡"""
        if self._initialized:
            return

        logger.info("åˆå§‹åŒ–æ ¸å¿ƒæœåŠ¡æ•´åˆå™¨...")

        try:
            # åˆå§‹åŒ–Qwenå¤šæ¨¡æ€æœåŠ¡
            qwen_config = RealQwenConfig(
                api_key=self.config.qwen_api_key,
                base_url=self.config.qwen_base_url,
                enable_image_analysis=self.config.enable_multimodal,
                enable_chart_analysis=self.config.enable_multimodal,
                enable_formula_extraction=self.config.enable_multimodal,
                enable_entity_extraction=self.config.enable_entity_extraction,
                timeout=self.config.timeout
            )
            self._services['qwen'] = RealQwenService(qwen_config)

            # åˆå§‹åŒ–åµŒå…¥æœåŠ¡
            self._services['embedding'] = QwenEmbeddingService()

            # åˆå§‹åŒ–å­˜å‚¨æœåŠ¡
            self._services['minio'] = MinIOService()
            self._services['milvus'] = MilvusService()
            self._services['neo4j'] = Neo4jService()

            # åˆå§‹åŒ–æ–‡æ¡£å»é‡æœåŠ¡
            self._services['deduplication'] = DocumentDeduplicationService()

            self._initialized = True
            logger.info("âœ… æ ¸å¿ƒæœåŠ¡æ•´åˆå™¨åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ æ ¸å¿ƒæœåŠ¡æ•´åˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _ensure_initialized(self):
        """ç¡®ä¿æœåŠ¡å·²åˆå§‹åŒ–"""
        if not self._initialized:
            raise RuntimeError("æœåŠ¡æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ initialize()")

    async def process_document_complete(self,
                                     file_content: bytes,
                                     filename: str,
                                     document_id: str) -> Dict[str, Any]:
        """
        å®Œæ•´çš„æ–‡æ¡£å¤„ç†æµæ°´çº¿
        æ•´åˆæ‰€æœ‰åˆ†æ•£çš„åŠŸèƒ½ï¼šä¸Šä¼ ã€è§£æã€åˆ†æã€å­˜å‚¨
        """
        self._ensure_initialized()

        logger.info(f"ğŸš€ å¼€å§‹å®Œæ•´æ–‡æ¡£å¤„ç†: {filename}")

        try:
            result = {
                'document_id': document_id,
                'filename': filename,
                'processing_start': datetime.now().isoformat(),
                'stages': {}
            }

            # é˜¶æ®µ1: æ–‡æ¡£ä¸Šä¼ å’Œå­˜å‚¨
            logger.info("ğŸ“¤ é˜¶æ®µ1: æ–‡æ¡£ä¸Šä¼ ...")
            file_path = f"documents/{datetime.now().strftime('%Y/%m/%d')}/{filename}"
            await self._services['minio'].upload_file(file_path, file_content)
            result['stages']['upload'] = {'status': 'completed', 'path': file_path}

            # é˜¶æ®µ2: å¤šæ¨¡æ€åˆ†æ
            logger.info("ğŸ§  é˜¶æ®µ2: å¤šæ¨¡æ€åˆ†æ...")
            analysis_result = await self._services['qwen'].analyze_document_multimodal(
                file_content, filename, []
            )
            result['stages']['analysis'] = {
                'status': 'completed',
                'models_used': ['qwen-vl-plus'],
                'sections': len(analysis_result.get('sections_analysis', [])),
                'images_found': len(analysis_result.get('images_found', [])),
                'charts_found': len(analysis_result.get('charts_found', [])),
                'formulas_found': len(analysis_result.get('formulas_found', []))
            }

            # é˜¶æ®µ3: å®ä½“å…³ç³»æŠ½å–
            logger.info("ğŸ”— é˜¶æ®µ3: å®ä½“å…³ç³»æŠ½å–...")
            entities = await self._services['qwen'].extract_entity_relationships(
                analysis_result.get('summary', '')
            )
            result['stages']['entities'] = {
                'status': 'completed',
                'count': len(entities) if entities else 0
            }

            # é˜¶æ®µ4: å‘é‡åµŒå…¥ç”Ÿæˆ
            logger.info("ğŸ”¢ é˜¶æ®µ4: å‘é‡åµŒå…¥ç”Ÿæˆ...")
            text_content = analysis_result.get('summary', '')
            if text_content:
                embeddings = await self._services['embedding'].generate_embeddings([text_content])
                result['stages']['embeddings'] = {
                    'status': 'completed',
                    'dimension': len(embeddings[0]) if embeddings else 0,
                    'model': 'text-embedding-v4'
                }

            # é˜¶æ®µ5: å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“å’ŒçŸ¥è¯†å›¾è°±
            logger.info("ğŸ’¾ é˜¶æ®µ5: æ•°æ®æŒä¹…åŒ–...")

            # å­˜å‚¨åˆ°Milvus
            if 'embeddings' in result and embeddings:
                await self._services['milvus'].insert_embeddings(
                    collection_name="document_embeddings",
                    embeddings=embeddings,
                    documents=[{
                        'id': document_id,
                        'filename': filename,
                        'content': text_content,
                        'metadata': json.dumps(analysis_result, ensure_ascii=False)
                    }]
                )

            # å­˜å‚¨åˆ°Neo4j
            if entities and self.config.enable_knowledge_graph:
                for entity in entities[:5]:  # é™åˆ¶æ•°é‡
                    await self._services['neo4j'].create_entity_node(
                        entity_id=f"{document_id}_{entity.get('name', '')}",
                        entity_type=entity.get('type', 'UNKNOWN'),
                        properties=entity
                    )

            result['stages']['storage'] = {'status': 'completed'}
            result['processing_end'] = datetime.now().isoformat()
            result['status'] = 'completed'
            result['success'] = True

            logger.info(f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆ: {filename}")
            return result

        except Exception as e:
            logger.error(f"âŒ æ–‡æ¡£å¤„ç†å¤±è´¥ {filename}: {e}")
            result['status'] = 'failed'
            result['error'] = str(e)
            result['success'] = False
            return result

    async def search_documents(self,
                            query: str,
                            top_k: int = 10,
                            filters: Optional[Dict] = None) -> List[Dict[str, Any]]:
        """
        ç»Ÿä¸€çš„æ–‡æ¡£æœç´¢æ¥å£
        æ•´åˆå‘é‡æœç´¢å’ŒçŸ¥è¯†å›¾è°±æœç´¢
        """
        self._ensure_initialized()

        try:
            # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
            query_embeddings = await self._services['embedding'].generate_embeddings([query])

            # å‘é‡æœç´¢
            search_results = await self._services['milvus'].search(
                collection_name="document_embeddings",
                query_vectors=query_embeddings,
                limit=top_k
            )

            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            for result in search_results:
                formatted_results.append({
                    'id': result.get('id', ''),
                    'filename': result.get('filename', ''),
                    'content': result.get('content', ''),
                    'score': result.get('score', 0.0),
                    'metadata': json.loads(result.get('metadata', '{}'))
                })

            return formatted_results

        except Exception as e:
            logger.error(f"æ–‡æ¡£æœç´¢å¤±è´¥: {e}")
            return []

    async def get_service_status(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰æœåŠ¡çš„çŠ¶æ€"""
        self._ensure_initialized()

        status = {
            'integrator': 'initialized',
            'services': {}
        }

        for name, service in self._services.items():
            try:
                # ç®€å•çš„å¥åº·æ£€æŸ¥
                status['services'][name] = 'healthy'
            except Exception as e:
                status['services'][name] = f'unhealthy: {e}'

        return status

    def get_config_summary(self) -> Dict[str, Any]:
        """è·å–é…ç½®æ‘˜è¦"""
        return {
            'multimodal_enabled': self.config.enable_multimodal,
            'entity_extraction_enabled': self.config.enable_entity_extraction,
            'knowledge_graph_enabled': self.config.enable_knowledge_graph,
            'max_workers': self.config.max_workers,
            'timeout': self.config.timeout
        }


# å…¨å±€æœåŠ¡æ•´åˆå™¨å®ä¾‹
_service_integrator = None


def get_service_integrator() -> CoreServiceIntegrator:
    """è·å–å…¨å±€æœåŠ¡æ•´åˆå™¨å®ä¾‹"""
    global _service_integrator
    if _service_integrator is None:
        _service_integrator = CoreServiceIntegrator()
    return _service_integrator