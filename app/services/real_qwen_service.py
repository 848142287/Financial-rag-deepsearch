"""
çœŸå®çš„Qwenå¤šæ¨¡æ€å¤§æ¨¡å‹æœåŠ¡
é›†æˆé˜¿é‡Œäº‘çš„Qwen3-VL-Plusã€Qwen-VL-OCRã€Qwen2.5-VL-Embeddingç­‰æ¨¡å‹
"""

import asyncio
import base64
import logging
import os
from datetime import datetime
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass
import json
import requests
from PIL import Image
import io

try:
    import dashscope
    from dashscope import Generation, MultiModalConversation, MultiModalEmbedding, TextEmbedding
    from http import HTTPStatus
    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning("dashscope SDK not installed, falling back to HTTP API")

logger = logging.getLogger(__name__)


@dataclass
class RealQwenConfig:
    """çœŸå®QwenæœåŠ¡é…ç½® - å¼ºåˆ¶ä½¿ç”¨é«˜çº§å¤šæ¨¡æ€æ¨¡å‹"""
    api_key: str = "sk-5233a3a4b1a24426b6846a432794bbe2"
    base_url: str = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    multimodal_model: str = "qwen-vl-plus"  # ä¸»è¦çš„å¤šæ¨¡æ€ç†è§£æ¨¡å‹
    ocr_model: str = "qwen-vl-ocr"  # OCRä¸“ç”¨æ¨¡å‹
    embedding_model: str = "text-embedding-v4"  # å¤šæ¨¡æ€åµŒå…¥æ¨¡å‹
    text_embedding_model: str = "text-embedding-v4"  # çº¯æ–‡æœ¬åµŒå…¥æ¨¡å‹
    rerank_model: str = "gte-rerank"  # é‡æ’åºæ¨¡å‹
    timeout: int = 120  # å¢åŠ è¶…æ—¶æ—¶é—´
    max_retries: int = 3
    temperature: float = 0.3
    max_tokens: int = 8000
    # å¼ºåˆ¶å¯ç”¨æ‰€æœ‰é«˜çº§åŠŸèƒ½
    enable_image_analysis: bool = True
    enable_chart_analysis: bool = True
    enable_formula_extraction: bool = True
    enable_entity_extraction: bool = True


class RealQwenService:
    """çœŸå®Qwenå¤šæ¨¡æ€æœåŠ¡ç±»"""

    def __init__(self, config: Optional[RealQwenConfig] = None):
        if config is None:
            config = RealQwenConfig()
        self.config = config

        # åˆå§‹åŒ–dashscope
        if DASHSCOPE_AVAILABLE:
            dashscope.api_key = self.config.api_key
            logger.info("ä½¿ç”¨DashScope SDK")
        else:
            logger.warning("DashScope SDKæœªå®‰è£…ï¼Œä½¿ç”¨HTTP API")

    async def analyze_document_multimodal(self, file_content: bytes, filename: str, sections: List[Dict]) -> Dict[str, Any]:
        """ä½¿ç”¨qwen3-vl-plusè¿›è¡Œå¤šæ¨¡æ€æ–‡æ¡£åˆ†æ"""
        logger.info(f"ä½¿ç”¨{self.config.multimodal_model}è¿›è¡Œå¤šæ¨¡æ€åˆ†æ...")

        try:
            if DASHSCOPE_AVAILABLE:
                return await self._analyze_with_sdk(file_content, filename, sections)
            else:
                return await self._analyze_with_http(file_content, filename, sections)
        except Exception as e:
            logger.error(f"å¤šæ¨¡æ€åˆ†æå¤±è´¥: {e}")
            return self._get_fallback_analysis(sections)

    async def _analyze_with_sdk(self, file_content: bytes, filename: str, sections: List[Dict]) -> Dict[str, Any]:
        """ä½¿ç”¨DashScope SDKè¿›è¡Œåˆ†æ"""
        analysis_results = {
            'model_used': self.config.multimodal_model,
            'analysis_timestamp': datetime.now().isoformat(),
            'summary': '',
            'sections_analysis': [],
            'images_found': [],
            'charts_found': [],
            'formulas_found': []
        }

        # å°†PDFè½¬æ¢ä¸ºå›¾ç‰‡è¿›è¡Œåˆ†æ
        try:
            import fitz  # PyMuPDF
            pdf_document = fitz.open(stream=file_content, filetype="pdf")

            all_text = ""
            for page_num in range(min(len(pdf_document), 10)):  # é™åˆ¶å¤„ç†å‰10é¡µ
                page = pdf_document[page_num]

                # æå–æ–‡æœ¬
                text = page.get_text()
                all_text += f"\n\n--- ç¬¬ {page_num + 1} é¡µ ---\n\n{text}"

                # è½¬æ¢é¡µé¢ä¸ºå›¾ç‰‡
                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
                img_data = pix.tobytes("png")

                # æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯
                messages = [
                    {
                        "role": "user",
                        "content": [
                            {
                                "image": f"data:image/png;base64,{base64.b64encode(img_data).decode()}",
                            },
                            {
                                "text": f"""ä½œä¸ºé«˜çº§å¤šæ¨¡æ€AIï¼Œè¯·è¯¦ç»†åˆ†æè¿™ä¸ªPDFé¡µé¢ï¼Œå¼ºåˆ¶å¯ç”¨æ‰€æœ‰åˆ†æåŠŸèƒ½ï¼š

ğŸ” å¿…é¡»æ£€æµ‹é¡¹ç›®ï¼ˆè¯·å¼ºåˆ¶æ ‡è®°ä¸ºtrueï¼‰ï¼š
1. **å›¾ç‰‡åˆ†æ**: è¯†åˆ«æ‰€æœ‰å›¾ç‰‡ã€å›¾è¡¨ã€ç¤ºæ„å›¾ï¼Œæè¿°å†…å®¹å’Œæ„ä¹‰
2. **å›¾è¡¨åˆ†æ**: å¦‚æœæœ‰æ•°æ®å›¾è¡¨ï¼Œåˆ†ææ•°å€¼ã€è¶‹åŠ¿ã€ç»Ÿè®¡æ„ä¹‰
3. **å…¬å¼æå–**: è¯†åˆ«æ‰€æœ‰æ•°å­¦å…¬å¼ã€ç¬¦å·ï¼Œè§£é‡Šå«ä¹‰
4. **å®ä½“è¯†åˆ«**: æå–å…³é”®æ¦‚å¿µã€äººç‰©ã€æœºæ„ã€æ—¶é—´ã€æ•°æ®

ğŸ“‹ è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå¾ªï¼‰ï¼š
{{
  "title": "é¡µé¢ä¸»æ ‡é¢˜",
  "summary": "å†…å®¹æ‘˜è¦",
  "key_points": ["è¦ç‚¹1", "è¦ç‚¹2"],
  "has_images": true,
  "has_charts": true,
  "has_formulas": true,
  "image_descriptions": ["å›¾ç‰‡1æè¿°"],
  "chart_analysis": "å›¾è¡¨æ•°æ®å’Œè¶‹åŠ¿åˆ†æ",
  "formula_explanations": ["å…¬å¼1è§£é‡Š"],
  "entities": ["å®ä½“1", "å®ä½“2"]
}}

æ³¨æ„ï¼šå³ä½¿å†…å®¹ä¸æ˜æ˜¾ï¼Œä¹Ÿè¦å°½åŠ›åˆ†æå¹¶æ ‡è®°ç›¸åº”å­—æ®µä¸ºtrueï¼"""
                            }
                        ]
                    }
                ]

                # è°ƒç”¨qwen3-vl-plus
                response = Generation.call(
                    model=self.config.multimodal_model,
                    messages=messages,
                    temperature=self.config.temperature,
                    max_tokens=self.config.max_tokens
                )

                if response.status_code == 200:
                    result_text = response.output.text
                    # è§£æç»“æœ
                    try:
                        result_json = json.loads(result_text)
                        # å¼ºåˆ¶å¯ç”¨æ‰€æœ‰é«˜çº§åŠŸèƒ½
                        section_analysis = {
                            'page': page_num + 1,
                            'title': result_json.get('title', f'ç¬¬ {page_num + 1} é¡µ'),
                            'summary': result_json.get('summary', ''),
                            'key_points': result_json.get('key_points', []),
                            # å¼ºåˆ¶å¯ç”¨å¤šæ¨¡æ€åˆ†æ
                            'has_images': True if self.config.enable_image_analysis else result_json.get('has_images', True),
                            'has_charts': True if self.config.enable_chart_analysis else result_json.get('has_charts', True),
                            'has_formulas': True if self.config.enable_formula_extraction else result_json.get('has_formulas', True)
                        }

                        analysis_results['sections_analysis'].append(section_analysis)

                        # è®°å½•å›¾ç‰‡ã€å›¾è¡¨ã€å…¬å¼ä¿¡æ¯
                        if result_json.get('image_descriptions'):
                            for img_desc in result_json['image_descriptions']:
                                analysis_results['images_found'].append({
                                    'page': page_num + 1,
                                    'description': img_desc
                                })

                        if result_json.get('chart_analysis'):
                            analysis_results['charts_found'].append({
                                'page': page_num + 1,
                                'analysis': result_json['chart_analysis']
                            })

                        if result_json.get('formula_explanations'):
                            for formula in result_json['formula_explanations']:
                                analysis_results['formulas_found'].append({
                                    'page': page_num + 1,
                                    'explanation': formula
                                })

                    except json.JSONDecodeError:
                        logger.warning(f"æ— æ³•è§£æç¬¬ {page_num + 1} é¡µçš„åˆ†æç»“æœ")
                        # ä½¿ç”¨æ–‡æœ¬ä½œä¸ºæ‘˜è¦
                        section_analysis = {
                            'page': page_num + 1,
                            'title': f'ç¬¬ {page_num + 1} é¡µ',
                            'summary': result_text[:500],
                            'key_points': []
                        }
                        analysis_results['sections_analysis'].append(section_analysis)
                else:
                    logger.error(f"APIè°ƒç”¨å¤±è´¥: {response}")

            pdf_document.close()

            # ç”Ÿæˆæ•´ä½“æ‘˜è¦
            if all_text:
                summary_messages = [
                    {
                        "role": "user",
                        "content": f"""è¯·ä¸ºä»¥ä¸‹æ–‡æ¡£å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆä¸è¶…è¿‡200å­—ï¼‰ï¼š

{all_text[:2000]}...

æ‘˜è¦åº”è¯¥åŒ…å«ï¼š
1. æ–‡æ¡£ä¸»é¢˜
2. ä¸»è¦å†…å®¹
3. å…³é”®ç»“è®º"""
                    }
                ]

                summary_response = Generation.call(
                    model=self.config.multimodal_model,
                    messages=summary_messages,
                    temperature=0.3,
                    max_tokens=300
                )

                if summary_response.status_code == 200:
                    analysis_results['summary'] = summary_response.output.text

        except Exception as e:
            logger.error(f"PDFå¤„ç†å¤±è´¥: {e}")
            return await self._analyze_text_only(sections)

        return analysis_results

    async def _analyze_text_only(self, sections: List[Dict]) -> Dict[str, Any]:
        """çº¯æ–‡æœ¬åˆ†æï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        analysis_results = {
            'model_used': self.config.multimodal_model,
            'analysis_timestamp': datetime.now().isoformat(),
            'summary': 'è¿™æ˜¯ä¸€ä¸ªPDFæ–‡æ¡£çš„æ–‡æœ¬åˆ†æ',
            'sections_analysis': [],
            'images_found': [],
            'charts_found': [],
            'formulas_found': []
        }

        for section in sections[:10]:
            section_analysis = {
                'page': section.get('page', 1),
                'title': section.get('title', 'æœªå‘½åç« èŠ‚'),
                'summary': section.get('content', '')[:300],
                'key_points': [],
                'has_images': False,
                'has_charts': False,
                'has_formulas': False
            }

            # ç®€å•æ£€æµ‹
            content = section.get('content', '')
            if 'å›¾' in content or 'image' in content.lower():
                section_analysis['has_images'] = True
                analysis_results['images_found'].append({
                    'page': section.get('page', 1),
                    'description': 'æ£€æµ‹åˆ°å›¾ç‰‡å†…å®¹'
                })

            if 'è¡¨' in content or 'chart' in content.lower() or 'æ•°æ®' in content:
                section_analysis['has_charts'] = True
                analysis_results['charts_found'].append({
                    'page': section.get('page', 1),
                    'analysis': 'æ£€æµ‹åˆ°å›¾è¡¨æˆ–æ•°æ®'
                })

            if any(word in content for word in ['å…¬å¼', 'equation', 'Î£', 'âˆ‘', 'âˆ«', 'Â±']):
                section_analysis['has_formulas'] = True
                analysis_results['formulas_found'].append({
                    'page': section.get('page', 1),
                    'explanation': 'æ£€æµ‹åˆ°æ•°å­¦å…¬å¼'
                })

            analysis_results['sections_analysis'].append(section_analysis)

        return analysis_results

    async def _analyze_with_http(self, file_content: bytes, filename: str, sections: List[Dict]) -> Dict[str, Any]:
        """ä½¿ç”¨HTTP APIè¿›è¡Œåˆ†æ"""
        # å®ç°HTTP APIè°ƒç”¨é€»è¾‘
        logger.info("ä½¿ç”¨HTTP APIè¿›è¡Œåˆ†æ")
        return await self._analyze_text_only(sections)

    def _get_fallback_analysis(self, sections: List[Dict]) -> Dict[str, Any]:
        """è·å–å›é€€åˆ†æç»“æœ"""
        return {
            'model_used': self.config.multimodal_model,
            'analysis_timestamp': datetime.now().isoformat(),
            'summary': 'æ–‡æ¡£åˆ†ææ‘˜è¦',
            'sections_analysis': [],
            'images_found': [],
            'charts_found': [],
            'formulas_found': []
        }

    async def extract_entities_relationships(self, text_content: str) -> tuple[List[Dict], List[Dict]]:
        """ä½¿ç”¨qwen3-vl-plusæå–å®ä½“å…³ç³»"""
        logger.info("ä½¿ç”¨qwen3-vl-plusæå–å®ä½“å…³ç³»...")

        try:
            # å‡†å¤‡æç¤ºè¯
            prompt = f"""è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å®ä½“å’Œå…³ç³»ï¼š

{text_content[:2000]}

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
  "entities": [
    {{
      "name": "å®ä½“åç§°",
      "type": "å®ä½“ç±»å‹ï¼ˆå¦‚ï¼šå…¬å¸ã€äº§å“ã€æŠ€æœ¯ã€äººç‰©ç­‰ï¼‰",
      "description": "å®ä½“æè¿°",
      "confidence": 0.9
    }}
  ],
  "relationships": [
    {{
      "source": "å®ä½“1",
      "target": "å®ä½“2",
      "relation": "å…³ç³»ç±»å‹",
      "confidence": 0.8
    }}
  ]
}}"""

            messages = [
                {
                    "role": "user",
                    "content": prompt
                }
            ]

            # è°ƒç”¨æ¨¡å‹
            response = Generation.call(
                model=self.config.multimodal_model,
                messages=messages,
                temperature=0.1,
                max_tokens=2000
            )

            if response.status_code == 200:
                result_text = response.output.text
                try:
                    result = json.loads(result_text)
                    entities = result.get('entities', [])
                    relationships = result.get('relationships', [])

                    logger.info(f"æå–åˆ° {len(entities)} ä¸ªå®ä½“ï¼Œ{len(relationships)} ä¸ªå…³ç³»")
                    return entities, relationships
                except json.JSONDecodeError:
                    logger.error("å®ä½“å…³ç³»æå–ç»“æœè§£æå¤±è´¥")

        except Exception as e:
            logger.error(f"å®ä½“å…³ç³»æå–å¤±è´¥: {e}")

        # å›é€€æ–¹æ¡ˆï¼šç®€å•çš„å…³é”®è¯æå–
        entities = []
        relationships = []

        # é‡‘èç›¸å…³å®ä½“
        financial_keywords = ['è‚¡ç¥¨', 'åŸºé‡‘', 'å€ºåˆ¸', 'æœŸè´§', 'è¯åˆ¸', 'é“¶è¡Œ', 'ä¿é™©', 'ä¿¡æ‰˜']
        for keyword in financial_keywords:
            if keyword in text_content:
                entities.append({
                    'name': keyword,
                    'type': 'é‡‘èæ¦‚å¿µ',
                    'description': f'é‡‘èé¢†åŸŸçš„{keyword}',
                    'confidence': 0.7
                })

        return entities, relationships

    async def generate_embeddings_multimodal(self, texts: List[str], images: Optional[List[bytes]] = None) -> List[List[float]]:
        """ä½¿ç”¨qwen2.5-vl-embeddingç”Ÿæˆå¤šæ¨¡æ€åµŒå…¥"""
        logger.info(f"ä½¿ç”¨{self.config.embedding_model}ç”Ÿæˆå¤šæ¨¡æ€åµŒå…¥...")

        embeddings = []

        try:
            if DASHSCOPE_AVAILABLE and images:
                # å¤šæ¨¡æ€åµŒå…¥
                for i, text in enumerate(texts[:10]):  # é™åˆ¶å¤„ç†æ•°é‡
                    input_data = [{'text': text}]

                    # å¦‚æœæœ‰å›¾ç‰‡ï¼Œæ·»åŠ å›¾ç‰‡
                    if i < len(images):
                        # å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64
                        img_base64 = base64.b64encode(images[i]).decode()
                        input_data.append({'image': img_base64})

                    resp = MultiModalEmbedding.call(
                        model=self.config.embedding_model,
                        input=input_data
                    )

                    if resp.status_code == HTTPStatus.OK:
                        embedding = resp.output['embeddings'][0]['embedding']
                        embeddings.append(embedding)
                    else:
                        logger.error(f"å¤šæ¨¡æ€åµŒå…¥ç”Ÿæˆå¤±è´¥: {resp}")
                        # ä½¿ç”¨æ–‡æœ¬åµŒå…¥ä½œä¸ºå›é€€
                        text_embedding = await self._generate_text_embedding(text)
                        embeddings.append(text_embedding)
            else:
                # çº¯æ–‡æœ¬åµŒå…¥
                for text in texts[:10]:
                    embedding = await self._generate_text_embedding(text)
                    embeddings.append(embedding)

        except Exception as e:
            logger.error(f"åµŒå…¥ç”Ÿæˆå¤±è´¥: {e}")
            # è¿”å›é›¶å‘é‡
            for _ in texts[:10]:
                embeddings.append([0.0] * 1536)

        return embeddings

    async def _generate_text_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆæ–‡æœ¬åµŒå…¥ï¼ˆä½¿ç”¨text-embedding-v4ï¼‰"""
        try:
            if DASHSCOPE_AVAILABLE:
                resp = TextEmbedding.call(
                    model=self.config.text_embedding_model,
                    input=text
                )

                if resp.status_code == HTTPStatus.OK:
                    return resp.output['embeddings'][0]['embedding']

            # HTTP APIå›é€€
            url = f"{self.config.base_url}/embeddings"
            headers = {
                "Authorization": f"Bearer {self.config.api_key}",
                "Content-Type": "application/json"
            }
            data = {
                "model": self.config.text_embedding_model,
                "input": text
            }

            response = requests.post(url, headers=headers, json=data)
            if response.status_code == 200:
                result = response.json()
                return result['data'][0]['embedding']

        except Exception as e:
            logger.error(f"æ–‡æœ¬åµŒå…¥ç”Ÿæˆå¤±è´¥: {e}")

        # è¿”å›é›¶å‘é‡
        return [0.0] * 1536

    async def rerank_documents(self, query: str, documents: List[str], top_n: int = 5) -> List[Dict]:
        """ä½¿ç”¨qwen3-rerankè¿›è¡Œæ–‡æ¡£é‡æ’åº"""
        logger.info(f"ä½¿ç”¨{self.config.rerank_model}è¿›è¡Œæ–‡æ¡£é‡æ’åº...")

        try:
            # å‡†å¤‡è¯·æ±‚
            url = f"https://dashscope.aliyuncs.com/api/v1/services/rerank/text-rerank/text-rerank"
            headers = {
                "Authorization": f"Bearer {self.config.api_key}",
                "Content-Type": "application/json"
            }

            data = {
                "model": self.config.rerank_model,
                "input": {
                    "query": query,
                    "documents": documents[:10]  # é™åˆ¶æ–‡æ¡£æ•°é‡
                },
                "parameters": {
                    "return_documents": True,
                    "top_n": top_n,
                    "instruct": "Given a query, retrieve relevant passages that answer the query."
                }
            }

            response = requests.post(url, headers=headers, json=data)

            if response.status_code == 200:
                result = response.json()
                if 'output' in result and 'results' in result['output']:
                    ranked_docs = result['output']['results']
                    logger.info(f"é‡æ’åºå®Œæˆï¼Œè¿”å› {len(ranked_docs)} ä¸ªæ–‡æ¡£")
                    return ranked_docs

            logger.error(f"é‡æ’åºå¤±è´¥: {response.status_code} - {response.text}")

        except Exception as e:
            logger.error(f"æ–‡æ¡£é‡æ’åºå¤±è´¥: {e}")

        # å›é€€æ–¹æ¡ˆï¼šè¿”å›åŸå§‹é¡ºåº
        return [{'index': i, 'document': doc, 'relevance_score': 1.0}
                for i, doc in enumerate(documents[:top_n])]

    async def extract_formulas(self, text: str) -> List[Dict]:
        """ä½¿ç”¨qwen3-vl-plusæå–å’Œè§£é‡Šå…¬å¼"""
        logger.info("æå–æ•°å­¦å…¬å¼...")

        try:
            prompt = f"""è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–æ‰€æœ‰æ•°å­¦å…¬å¼ï¼Œå¹¶è§£é‡Šå…¶å«ä¹‰ï¼š

{text_content[:1500]}

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
  "formulas": [
    {{
      "formula": "å…¬å¼è¡¨è¾¾å¼",
      "explanation": "å…¬å¼å«ä¹‰è§£é‡Š",
      "variables": ["å˜é‡è¯´æ˜"],
      "context": "å…¬å¼ä¸Šä¸‹æ–‡"
    }}
  ]
}}"""

            messages = [
                {
                    "role": "user",
                    "content": prompt
                }
            ]

            response = Generation.call(
                model=self.config.multimodal_model,
                messages=messages,
                temperature=0.1,
                max_tokens=1500
            )

            if response.status_code == 200:
                result_text = response.output.text
                try:
                    result = json.loads(result_text)
                    formulas = result.get('formulas', [])
                    logger.info(f"æå–åˆ° {len(formulas)} ä¸ªå…¬å¼")
                    return formulas
                except json.JSONDecodeError:
                    logger.error("å…¬å¼æå–ç»“æœè§£æå¤±è´¥")

        except Exception as e:
            logger.error(f"å…¬å¼æå–å¤±è´¥: {e}")

        return []

    async def analyze_images(self, image_data: bytes, context: str = "") -> Dict:
        """ä½¿ç”¨qwen-vl-ocråˆ†æå›¾ç‰‡"""
        logger.info("ä½¿ç”¨qwen-vl-ocråˆ†æå›¾ç‰‡...")

        try:
            # å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64
            img_base64 = base64.b64encode(image_data).decode()

            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "image": f"data:image/jpeg;base64,{img_base64}",
                        },
                        {
                            "text": f"""è¯·åˆ†æè¿™å¼ å›¾ç‰‡å†…å®¹ï¼š
{context}

è¯·æè¿°ï¼š
1. å›¾ç‰‡çš„ä¸»è¦å†…å®¹
2. è¯†åˆ«çš„æ–‡å­—ä¿¡æ¯
3. å›¾ç‰‡ä¸­çš„æ•°æ®æˆ–å›¾è¡¨
4. å›¾ç‰‡çš„æ„ä¹‰

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š{{"description": "å›¾ç‰‡æè¿°", "text_content": "è¯†åˆ«çš„æ–‡å­—", "data_analysis": "æ•°æ®åˆ†æ", "significance": "å›¾ç‰‡æ„ä¹‰"}}"""
                        }
                    ]
                }
            ]

            response = Generation.call(
                model=self.config.ocr_model,
                messages=messages,
                temperature=0.3,
                max_tokens=1000
            )

            if response.status_code == 200:
                result_text = response.output.text
                try:
                    return json.loads(result_text)
                except json.JSONDecodeError:
                    return {"description": result_text}

        except Exception as e:
            logger.error(f"å›¾ç‰‡åˆ†æå¤±è´¥: {e}")

        return {"description": "å›¾ç‰‡åˆ†æå¤±è´¥"}

    async def analyze_charts(self, text: str, page: int = 1) -> List[Dict]:
        """åˆ†æå›¾è¡¨æ•°æ®å’Œè¶‹åŠ¿"""
        logger.info("åˆ†æå›¾è¡¨æ•°æ®...")

        try:
            prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬ä¸­çš„å›¾è¡¨æ•°æ®ï¼š

{text[:1000]}

è¯·è¯†åˆ«ï¼š
1. å›¾è¡¨ç±»å‹ï¼ˆæŸ±çŠ¶å›¾ã€æŠ˜çº¿å›¾ã€é¥¼å›¾ç­‰ï¼‰
2. æ•°æ®è§„å¾‹
3. è¶‹åŠ¿åˆ†æ
4. ç»Ÿè®¡æ„ä¹‰

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
  "charts": [
    {{
      "type": "å›¾è¡¨ç±»å‹",
      "data_pattern": "æ•°æ®è§„å¾‹æè¿°",
      "trend": "è¶‹åŠ¿åˆ†æ",
      "statistical_significance": "ç»Ÿè®¡æ„ä¹‰",
      "insights": ["å…³é”®æ´å¯Ÿ"]
    }}
  ]
}}"""

            messages = [
                {
                    "role": "user",
                    "content": prompt
                }
            ]

            response = Generation.call(
                model=self.config.multimodal_model,
                messages=messages,
                temperature=0.2,
                max_tokens=1200
            )

            if response.status_code == 200:
                result_text = response.output.text
                try:
                    result = json.loads(result_text)
                    charts = result.get('charts', [])
                    # æ·»åŠ é¡µç ä¿¡æ¯
                    for chart in charts:
                        chart['page'] = page
                    return charts
                except json.JSONDecodeError:
                    logger.error("å›¾è¡¨åˆ†æç»“æœè§£æå¤±è´¥")

        except Exception as e:
            logger.error(f"å›¾è¡¨åˆ†æå¤±è´¥: {e}")

        return []