"""
æ··åˆæ£€ç´¢æœåŠ¡
å€Ÿé‰´DocMindé¡¹ç›®çš„ä¸‰è·¯æ··åˆæ£€ç´¢æ¶æ„ï¼š
- Path A: HyDEå‘é‡æ£€ç´¢
- Path B: è¯­ä¹‰å‘é‡æ£€ç´¢
- Path C: BM25å…³é”®è¯æ£€ç´¢
"""

from dataclasses import dataclass, field
from app.core.structured_logging import get_structured_logger
from app.services.rag.retrieval.enhanced_query_processor import (
    get_query_processor,
    ProcessedQuery
)
from app.services.rag.retrieval.bge_reranker_service import (
    get_bge_reranker_service,
    ThreeLevelConfidenceFilter
)

logger = get_structured_logger(__name__)

@dataclass
class RetrievalResult:
    """æ£€ç´¢ç»“æœ"""
    doc_id: str
    content: str
    score: float
    confidence: str  # high/medium/low
    source: str  # æ¥æºè·¯å¾„æ ‡è¯†
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class HybridRetrievalConfig:
    """æ··åˆæ£€ç´¢é…ç½®"""
    # å¬å›é…ç½®
    candidate_multiplier: int = 3  # æ¯æ¡è·¯å¬å› top_k * multiplier
    enable_hyde: bool = True  # å¯ç”¨HyDEè·¯å¾„
    enable_semantic: bool = True  # å¯ç”¨è¯­ä¹‰æ£€ç´¢è·¯å¾„
    enable_bm25: bool = True  # å¯ç”¨BM25è·¯å¾„

    # Rerankeré…ç½®
    enable_rerank: bool = True
    score_bias: float = 4.0  # Sigmoidåå·®

    # ç½®ä¿¡åº¦è¿‡æ»¤
    enable_confidence_filter: bool = True
    threshold_low: float = 4.0
    threshold_high: float = 6.0

    # å…³é”®è¯ç¡¬è¿‡æ»¤
    enable_keyword_filter: bool = True
    keyword_high_score_threshold: float = 8.5  # é«˜åˆ†è±å…é˜ˆå€¼

class HybridRetrievalService:
    """
    æ··åˆæ£€ç´¢æœåŠ¡

    ä¸‰è·¯å¬å› + Reranker + ç½®ä¿¡åº¦è¿‡æ»¤
    """

    def __init__(
        self,
        vector_store=None,
        bm25_store=None,
        config: HybridRetrievalConfig = None
    ):
        """
        åˆå§‹åŒ–æ··åˆæ£€ç´¢æœåŠ¡

        Args:
            vector_store: å‘é‡å­˜å‚¨å®ä¾‹
            bm25_store: BM25å­˜å‚¨å®ä¾‹
            config: æ£€ç´¢é…ç½®
        """
        self.vector_store = vector_store
        self.bm25_store = bm25_store
        self.config = config or HybridRetrievalConfig()

        self.query_processor = get_query_processor()
        self.reranker = get_bge_reranker_service()
        self.confidence_filter = ThreeLevelConfidenceFilter(
            threshold_low=self.config.threshold_low,
            threshold_high=self.config.threshold_high
        )

        logger.info(
            f"HybridRetrievalServiceåˆå§‹åŒ–: "
            f"hyde={self.config.enable_hyde}, "
            f"semantic={self.config.enable_semantic}, "
            f"bm25={self.config.enable_bm25}, "
            f"rerank={self.config.enable_rerank}"
        )

    async def retrieve(
        self,
        query: str,
        top_k: int = 5,
        history: List[Dict[str, str]] = None,
        filters: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ··åˆæ£€ç´¢

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            top_k: è¿”å›ç»“æœæ•°é‡
            history: å¯¹è¯å†å²
            filters: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶

        Returns:
            {
                "results": List[RetrievalResult],
                "query_info": ProcessedQuery,
                "stats": Dict,
                "direct_answer": Optional[str]  # å…ƒé—®é¢˜çš„ç›´æ¥å›ç­”
            }
        """
        logger.info(f"ğŸ” å¼€å§‹æ··åˆæ£€ç´¢: query='{query}', top_k={top_k}")

        # 1. æŸ¥è¯¢å¤„ç†
        processed_query = await self.query_processor.process(query, history)

        # å¦‚æœæ˜¯å…ƒé—®é¢˜ï¼Œç›´æ¥è¿”å›
        if processed_query.is_meta_question:
            return {
                "results": [],
                "query_info": processed_query,
                "stats": {},
                "direct_answer": processed_query.direct_answer
            }

        # 2. ä¸‰è·¯å¬å›
        candidates = await self._three_way_recall(processed_query, top_k, filters)

        logger.info(f"ğŸ“Š ä¸‰è·¯å¬å›å®Œæˆ: candidates={len(candidates)}")

        # 3. Rerankeré‡æ’åº
        if self.config.enable_rerank and candidates:
            reranked = await self._rerank_candidates(query, candidates, top_k)
        else:
            reranked = candidates[:top_k]

        logger.info(f"ğŸ”„ Rerankerå®Œæˆ: reranked={len(reranked)}")

        # 4. å…³é”®è¯ç¡¬è¿‡æ»¤
        if self.config.enable_keyword_filter and processed_query.keywords:
            filtered = self._keyword_hard_filter(
                reranked,
                processed_query.keywords,
                query
            )
        else:
            filtered = reranked

        logger.info(f"ğŸ”‘ å…³é”®è¯è¿‡æ»¤å®Œæˆ: filtered={len(filtered)}")

        # 5. ç½®ä¿¡åº¦è¿‡æ»¤
        if self.config.enable_confidence_filter:
            final_results = self._apply_confidence_filter(filtered)
        else:
            final_results = [
                RetrievalResult(
                    doc_id=r["doc_id"],
                    content=r["content"],
                    score=r["score"],
                    confidence="unknown",
                    source=r.get("source", "unknown"),
                    metadata=r.get("metadata", {})
                )
                for r in filtered
            ]

        logger.info(
            f"âœ… æ··åˆæ£€ç´¢å®Œæˆ: final_results={len(final_results)}, "
            f"avg_score={sum(r.score for r in final_results)/len(final_results) if final_results else 0:.2f}"
        )

        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            "candidates": len(candidates),
            "after_rerank": len(reranked),
            "after_keyword_filter": len(filtered),
            "final": len(final_results),
            "avg_score": sum(r.score for r in final_results) / len(final_results) if final_results else 0,
            "confidence_distribution": self._get_confidence_distribution(final_results)
        }

        return {
            "results": final_results[:top_k],
            "query_info": processed_query,
            "stats": stats,
            "direct_answer": None
        }

    async def _three_way_recall(
        self,
        processed_query: ProcessedQuery,
        top_k: int,
        filters: Dict[str, Any] = None
    ) -> List[Dict[str, Any]]:
        """
        ä¸‰è·¯å¬å›

        Path A: HyDEå‘é‡æ£€ç´¢
        Path B: è¯­ä¹‰å‘é‡æ£€ç´¢
        Path C: BM25å…³é”®è¯æ£€ç´¢
        """
        candidate_k = top_k * self.config.candidate_multiplier
        candidates = {}  # {doc_id: best_score, metadata}

        # Path A: HyDEå‘é‡æ£€ç´¢
        if self.config.enable_hyde and self.vector_store and processed_query.hyde_doc:
            hyde_results = await self._vector_search(
                processed_query.hyde_doc,
                candidate_k,
                filters,
                source="hyde"
            )
            for r in hyde_results:
                self._merge_candidate(candidates, r)

            logger.debug(f"HyDEè·¯å¾„: å¬å›{len(hyde_results)}ä¸ª")

        # Path B: è¯­ä¹‰å‘é‡æ£€ç´¢
        if self.config.enable_semantic and self.vector_store:
            semantic_results = await self._vector_search(
                processed_query.vector_query,
                candidate_k,
                filters,
                source="semantic"
            )
            for r in semantic_results:
                self._merge_candidate(candidates, r)

            logger.debug(f"è¯­ä¹‰è·¯å¾„: å¬å›{len(semantic_results)}ä¸ª")

        # Path C: BM25å…³é”®è¯æ£€ç´¢
        if self.config.enable_bm25 and self.bm25_store:
            bm25_results = await self._bm25_search(
                [processed_query.standalone_query] + processed_query.keywords,
                candidate_k,
                filters
            )
            for r in bm25_results:
                self._merge_candidate(candidates, r)

            logger.debug(f"BM25è·¯å¾„: å¬å›{len(bm25_results)}ä¸ª")

        # è½¬æ¢ä¸ºåˆ—è¡¨
        return [
            {
                "doc_id": doc_id,
                "content": data["content"],
                "score": data["score"],
                "source": data["source"],
                "metadata": data.get("metadata", {})
            }
            for doc_id, data in candidates.items()
        ]

    def _merge_candidate(
        self,
        candidates: Dict[str, Dict],
        new_result: Dict[str, Any]
    ):
        """
        åˆå¹¶å€™é€‰ç»“æœï¼Œä¿ç•™æœ€é«˜åˆ†æ•°

        Args:
            candidates: {doc_id: {content, score, source, metadata}}
            new_result: {"doc_id", "content", "score", "source", "metadata"}
        """
        doc_id = new_result["doc_id"]

        if doc_id not in candidates:
            candidates[doc_id] = {
                "content": new_result["content"],
                "score": new_result["score"],
                "source": new_result["source"],
                "metadata": new_result.get("metadata", {})
            }
        else:
            # ä¿ç•™æ›´é«˜åˆ†æ•°çš„ç»“æœ
            if new_result["score"] > candidates[doc_id]["score"]:
                candidates[doc_id]["score"] = new_result["score"]
                candidates[doc_id]["source"] = new_result["source"]

    async def _vector_search(
        self,
        query: str,
        top_k: int,
        filters: Dict[str, Any],
        source: str
    ) -> List[Dict[str, Any]]:
        """
        å‘é‡æ£€ç´¢

        æ³¨ï¼šè¿™æ˜¯æ¥å£å®šä¹‰ï¼Œå®é™…å®ç°éœ€è¦è°ƒç”¨å…·ä½“çš„vector store
        """
        # TODO: è°ƒç”¨å®é™…çš„vector store
        # è¿™é‡Œè¿”å›æ¨¡æ‹Ÿç»“æœ
        return []

    async def _bm25_search(
        self,
        queries: List[str],
        top_k: int,
        filters: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        BM25æ£€ç´¢

        æ³¨ï¼šè¿™æ˜¯æ¥å£å®šä¹‰ï¼Œå®é™…å®ç°éœ€è¦è°ƒç”¨å…·ä½“çš„BM25 store
        """
        # TODO: è°ƒç”¨å®é™…çš„BM25 store
        # è¿™é‡Œè¿”å›æ¨¡æ‹Ÿç»“æœ
        return []

    async def _rerank_candidates(
        self,
        query: str,
        candidates: List[Dict[str, Any]],
        top_k: int
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨BGE Rerankeré‡æ’åº
        """
        if not candidates:
            return []

        # æå–æ–‡æ¡£å†…å®¹
        documents = [c["content"] for c in candidates]

        # Rerank
        rerank_scores = self.reranker.rerank(query, documents, top_k=None)

        # æ›´æ–°åˆ†æ•°
        for i, (idx, score) in enumerate(rerank_scores):
            candidates[idx]["score"] = score

        # æŒ‰åˆ†æ•°æ’åº
        candidates.sort(key=lambda x: x["score"], reverse=True)

        return candidates

    def _keyword_hard_filter(
        self,
        results: List[Dict[str, Any]],
        keywords: List[str],
        query: str
    ) -> List[Dict[str, Any]]:
        """
        å…³é”®è¯ç¡¬è¿‡æ»¤

        è§„åˆ™ï¼š
        1. å¦‚æœæ–‡æ¡£åŒ…å«ä»»ä¸€å…³é”®è¯ï¼Œä¿ç•™
        2. å¦‚æœrerankåˆ†æ•° > thresholdï¼Œç›´æ¥ä¿ç•™ï¼ˆé«˜åˆ†è±å…ï¼‰
        """
        filtered = []

        for r in results:
            # é«˜åˆ†è±å…
            if r["score"] >= self.config.keyword_high_score_threshold:
                filtered.append(r)
                continue

            # å…³é”®è¯æ£€æŸ¥
            content_lower = r["content"].lower()
            if any(kw.lower() in content_lower for kw in keywords):
                filtered.append(r)

        return filtered

    def _apply_confidence_filter(
        self,
        results: List[Dict[str, Any]]
    ) -> List[RetrievalResult]:
        """
        åº”ç”¨ç½®ä¿¡åº¦è¿‡æ»¤
        """
        # è½¬æ¢ä¸ºå…ƒç»„æ ¼å¼
        tuples = [
            (i, r["score"], {"content": r["content"], "metadata": r.get("metadata", {})})
            for i, r in enumerate(results)
        ]

        # è¿‡æ»¤å¹¶åˆ†ç±»
        filtered = self.confidence_filter.filter_and_classify(tuples)

        # è½¬æ¢ä¸ºRetrievalResult
        return [
            RetrievalResult(
                doc_id=results[idx]["doc_id"],
                content=metadata["content"],
                score=score,
                confidence=confidence,
                source=results[idx].get("source", "unknown"),
                metadata=metadata.get("metadata", {})
            )
            for idx, score, metadata, confidence in filtered
        ]

    def _get_confidence_distribution(
        self,
        results: List[RetrievalResult]
    ) -> Dict[str, int]:
        """è·å–ç½®ä¿¡åº¦åˆ†å¸ƒ"""
        dist = {"high": 0, "medium": 0, "low": 0}
        for r in results:
            dist[r.confidence] = dist.get(r.confidence, 0) + 1
        return dist

# å…¨å±€å®ä¾‹
_hybrid_retrieval_service = None

def get_hybrid_retrieval_service(
    vector_store=None,
    bm25_store=None,
    config: HybridRetrievalConfig = None
) -> HybridRetrievalService:
    """è·å–æ··åˆæ£€ç´¢æœåŠ¡å•ä¾‹"""
    global _hybrid_retrieval_service
    if _hybrid_retrieval_service is None:
        _hybrid_retrieval_service = HybridRetrievalService(
            vector_store=vector_store,
            bm25_store=bm25_store,
            config=config
        )
    return _hybrid_retrieval_service
