"""
æ™ºèƒ½æ–‡æ¡£åˆ†å—æœåŠ¡
æ”¯æŒå¤šç§åˆ†å—ç­–ç•¥ï¼Œæå‡æ£€ç´¢è´¨é‡
"""

from typing import List, Dict, Any, Optional
from enum import Enum
from app.core.structured_logging import get_structured_logger
import re

logger = get_structured_logger(__name__)


class ChunkingStrategy(Enum):
    """åˆ†å—ç­–ç•¥"""
    FIXED_SIZE = "fixed_size"  # å›ºå®šå¤§å°åˆ†å—
    SEMANTIC = "semantic"  # è¯­ä¹‰åˆ†å—
    INTELLIGENT = "intelligent"  # æ™ºèƒ½åˆ†å—
    HYBRID = "hybrid"  # æ··åˆåˆ†å—
    RECURSIVE = "recursive"  # é€’å½’åˆ†å—


class SmartChunkingService:
    """
    æ™ºèƒ½åˆ†å—æœåŠ¡

    åŠŸèƒ½ï¼š
    1. å¤šç§åˆ†å—ç­–ç•¥ï¼ˆå›ºå®šå¤§å°ã€è¯­ä¹‰ã€æ™ºèƒ½ã€æ··åˆï¼‰
    2. ä¸Šä¸‹æ–‡ä¿æŒï¼ˆé¿å…ä¿¡æ¯ä¸¢å¤±ï¼‰
    3. é‡‘èé¢†åŸŸä¼˜åŒ–ï¼ˆä¿ç•™æ•°å€¼ã€è¡¨æ ¼ï¼‰
    4. è‡ªé€‚åº”åˆ†å—ï¼ˆæ ¹æ®å†…å®¹è°ƒæ•´ï¼‰
    5. è´¨é‡æ£€æŸ¥ï¼ˆchunkå®Œæ•´æ€§ï¼‰
    """

    def __init__(self, default_strategy: ChunkingStrategy = ChunkingStrategy.INTELLIGENT):
        """
        Args:
            default_strategy: é»˜è®¤åˆ†å—ç­–ç•¥
        """
        self.default_strategy = default_strategy

        # é‡‘èæ–‡æ¡£çš„ç‰¹æ®Šæ¨¡å¼
        self.financial_patterns = {
            'table_start': r'\|[\s\w|]+\|',
            'list_start': r'^\s*[\d\-\â€¢\*]+\s',
            'section_header': r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+ã€|\d+\.\s+',
            'date': r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥|\d{4}/\d{1,2}/\d{1,2}',
            'number': r'\d+\.?\d*\s*[äº¿å…ƒåƒç™¾ä¸‡å…ƒ%]?',
        }

    def chunk_document(
        self,
        text: str,
        strategy: Optional[ChunkingStrategy] = None,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        åˆ†å—æ–‡æ¡£

        Args:
            text: æ–‡æ¡£å†…å®¹
            strategy: åˆ†å—ç­–ç•¥
            **kwargs: ç­–ç•¥å‚æ•°

        Returns:
            æ–‡æ¡£å—åˆ—è¡¨
        """
        strategy = strategy or self.default_strategy

        logger.info(f"ğŸ“ ä½¿ç”¨ç­–ç•¥ {strategy.value} åˆ†å—æ–‡æ¡£")

        if strategy == ChunkingStrategy.FIXED_SIZE:
            return self._fixed_size_chunk(text, **kwargs)
        elif strategy == ChunkingStrategy.SEMANTIC:
            return self._semantic_chunk(text, **kwargs)
        elif strategy == ChunkingStrategy.INTELLIGENT:
            return self._intelligent_chunk(text, **kwargs)
        elif strategy == ChunkingStrategy.HYBRID:
            return self._hybrid_chunk(text, **kwargs)
        elif strategy == ChunkingStrategy.RECURSIVE:
            return self._recursive_chunk(text, **kwargs)
        else:
            logger.warning(f"âš ï¸ æœªçŸ¥ç­–ç•¥ {strategy}ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥")
            return self._intelligent_chunk(text, **kwargs)

    def _fixed_size_chunk(
        self,
        text: str,
        chunk_size: int = 500,
        overlap: int = 50,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        å›ºå®šå¤§å°åˆ†å—

        Args:
            text: æ–‡æ¡£å†…å®¹
            chunk_size: å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
            overlap: é‡å å¤§å°

        Returns:
            æ–‡æ¡£å—åˆ—è¡¨
        """
        chunks = []
        start = 0
        chunk_index = 0

        while start < len(text):
            end = start + chunk_size

            # æˆªå–æ–‡æœ¬
            chunk_text = text[start:end]

            chunks.append({
                'index': chunk_index,
                'text': chunk_text,
                'start_pos': start,
                'end_pos': end,
                'strategy': 'fixed_size',
                'metadata': {
                    'size': len(chunk_text),
                    'overlap': overlap if start > 0 else 0
                }
            })

            start = end - overlap
            chunk_index += 1

        logger.info(f"âœ… å›ºå®šå¤§å°åˆ†å—å®Œæˆ: {len(chunks)}ä¸ªå—")
        return chunks

    def _semantic_chunk(
        self,
        text: str,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        è¯­ä¹‰åˆ†å—ï¼ˆæŒ‰æ®µè½ã€å¥å­ï¼‰

        Args:
            text: æ–‡æ¡£å†…å®¹

        Returns:
            æ–‡æ¡£å—åˆ—è¡¨
        """
        chunks = []
        chunk_index = 0

        # 1. æŒ‰æ®µè½åˆ†å‰²
        paragraphs = re.split(r'\n\s*\n', text)

        for paragraph in paragraphs:
            if not paragraph.strip():
                continue

            # å¦‚æœæ®µè½å¤ªé•¿ï¼ŒæŒ‰å¥å­åˆ†å‰²
            if len(paragraph) > 1000:
                sentences = self._split_into_sentences(paragraph)
                current_chunk = ""

                for sentence in sentences:
                    if len(current_chunk) + len(sentence) < 800:
                        current_chunk += sentence
                    else:
                        if current_chunk:
                            chunks.append({
                                'index': chunk_index,
                                'text': current_chunk.strip(),
                                'strategy': 'semantic',
                                'metadata': {
                                    'type': 'paragraph',
                                    'size': len(current_chunk)
                                }
                            })
                            chunk_index += 1
                        current_chunk = sentence

                if current_chunk:
                    chunks.append({
                        'index': chunk_index,
                        'text': current_chunk.strip(),
                        'strategy': 'semantic',
                        'metadata': {
                            'type': 'paragraph',
                            'size': len(current_chunk)
                        }
                    })
                    chunk_index += 1
            else:
                # ç›´æ¥ä½œä¸ºä¸€å—
                chunks.append({
                    'index': chunk_index,
                    'text': paragraph.strip(),
                    'strategy': 'semantic',
                    'metadata': {
                        'type': 'paragraph',
                        'size': len(paragraph.strip())
                    }
                })
                chunk_index += 1

        logger.info(f"âœ… è¯­ä¹‰åˆ†å—å®Œæˆ: {len(chunks)}ä¸ªå—")
        return chunks

    def _intelligent_chunk(
        self,
        text: str,
        target_chunk_size: int = 800,
        max_chunk_size: int = 1500,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        æ™ºèƒ½åˆ†å—ï¼ˆç»“åˆè¯­ä¹‰å’Œè§„åˆ™ï¼‰

        ä¼˜åŒ–ç‚¹ï¼š
        1. è¯†åˆ«è¡¨æ ¼ï¼Œä¿æŒå®Œæ•´
        2. è¯†åˆ«åˆ—è¡¨ï¼Œä¿æŒå®Œæ•´
        3. è¯†åˆ«ç« èŠ‚æ ‡é¢˜
        4. è¯†åˆ«é‡‘èæ•°æ®
        5. è‡ªé€‚åº”å¤§å°

        Args:
            text: æ–‡æ¡£å†…å®¹
            target_chunk_size: ç›®æ ‡å—å¤§å°
            max_chunk_size: æœ€å¤§å—å¤§å°

        Returns:
            æ–‡æ¡£å—åˆ—è¡¨
        """
        chunks = []
        chunk_index = 0

        # 1. è¯†åˆ«ç‰¹æ®Šç»“æ„
        structures = self._identify_structures(text)

        # 2. æŒ‰ç»“æ„åˆ†å—
        current_chunk = ""
        current_size = 0

        lines = text.split('\n')
        i = 0

        while i < len(lines):
            line = lines[i]
            line_num = i

            # æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹æ®Šç»“æ„çš„å¼€å§‹
            if line_num in structures:
                structure = structures[line_num]

                # å¦‚æœå½“å‰å—éç©ºï¼Œå…ˆä¿å­˜
                if current_chunk.strip():
                    chunks.append(self._create_chunk(
                        chunk_index,
                        current_chunk.strip(),
                        'intelligent',
                        {'type': 'mixed', 'size': len(current_chunk.strip())}
                    ))
                    chunk_index += 1
                    current_chunk = ""
                    current_size = 0

                # æ·»åŠ æ•´ä¸ªç»“æ„ä½œä¸ºä¸€ä¸ªå—
                chunks.append(self._create_chunk(
                    chunk_index,
                    structure['content'],
                    'intelligent',
                    {
                        'type': structure['type'],
                        'size': len(structure['content']),
                        'preserved': True
                    }
                ))
                chunk_index += 1

                # è·³è¿‡ç»“æ„ä¸­çš„è¡Œ
                i = structure['end_line'] + 1
                continue

            # æ™®é€šè¡Œï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å—
            if current_size + len(line) > target_chunk_size:
                # å¯»æ‰¾æœ€ä½³åˆ‡åˆ†ç‚¹
                if self._is_good_break_point(line):
                    # åœ¨è¿™é‡Œåˆ‡åˆ†
                    current_chunk += line
                    chunks.append(self._create_chunk(
                        chunk_index,
                        current_chunk.strip(),
                        'intelligent',
                        {'type': 'text', 'size': len(current_chunk.strip())}
                    ))
                    chunk_index += 1
                    current_chunk = ""
                    current_size = 0
                elif current_size > max_chunk_size:
                    # å¼ºåˆ¶åˆ‡åˆ†
                    chunks.append(self._create_chunk(
                        chunk_index,
                        current_chunk.strip(),
                        'intelligent',
                        {'type': 'text', 'size': len(current_chunk.strip())}
                    ))
                    chunk_index += 1
                    current_chunk = line
                    current_size = len(line)
                else:
                    # ç»§ç»­ç´¯åŠ 
                    current_chunk += line + '\n'
                    current_size += len(line) + 1
            else:
                # ç»§ç»­ç´¯åŠ 
                current_chunk += line + '\n'
                current_size += len(line) + 1

            i += 1

        # ä¿å­˜æœ€åä¸€å—
        if current_chunk.strip():
            chunks.append(self._create_chunk(
                chunk_index,
                current_chunk.strip(),
                'intelligent',
                {'type': 'text', 'size': len(current_chunk.strip())}
            ))

        logger.info(f"âœ… æ™ºèƒ½åˆ†å—å®Œæˆ: {len(chunks)}ä¸ªå—")
        return chunks

    def _identify_structures(self, text: str) -> Dict[int, Dict[str, Any]]:
        """è¯†åˆ«æ–‡æ¡£ä¸­çš„ç‰¹æ®Šç»“æ„ï¼ˆè¡¨æ ¼ã€åˆ—è¡¨ç­‰ï¼‰"""
        structures = {}
        lines = text.split('\n')

        i = 0
        while i < len(lines):
            line = lines[i]

            # æ£€æµ‹è¡¨æ ¼ï¼ˆMarkdownæ ¼å¼ï¼‰
            if re.match(self.financial_patterns['table_start'], line):
                start_line = i
                # æ‰¾åˆ°è¡¨æ ¼ç»“æŸ
                while i < len(lines) and (lines[i].strip().startswith('|') or lines[i].strip() == ''):
                    i += 1
                end_line = i - 1

                # è®°å½•è¡¨æ ¼ç»“æ„
                table_content = '\n'.join(lines[start_line:end_line + 1])
                structures[start_line] = {
                    'type': 'table',
                    'content': table_content,
                    'start_line': start_line,
                    'end_line': end_line
                }
                continue

            # æ£€æµ‹åˆ—è¡¨
            if re.match(self.financial_patterns['list_start'], line):
                start_line = i
                # æ‰¾åˆ°åˆ—è¡¨ç»“æŸ
                while i < len(lines) and re.match(self.financial_patterns['list_start'], lines[i]):
                    i += 1
                end_line = i - 1

                # è®°å½•åˆ—è¡¨ç»“æ„
                list_content = '\n'.join(lines[start_line:end_line + 1])
                structures[start_line] = {
                    'type': 'list',
                    'content': list_content,
                    'start_line': start_line,
                    'end_line': end_line
                }
                continue

            i += 1

        return structures

    def _is_good_break_point(self, line: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯å¥½çš„åˆ‡åˆ†ç‚¹"""
        # å¥å­ç»“å°¾
        if re.search(r'[ã€‚ï¼ï¼Ÿ\.!?]$', line):
            return True
        # æ®µè½ç»“æŸï¼ˆç©ºè¡Œï¼‰
        if not line.strip():
            return True
        return False

    def _split_into_sentences(self, text: str) -> List[str]:
        """å°†æ–‡æœ¬åˆ†å‰²æˆå¥å­"""
        # æŒ‰ä¸­è‹±æ–‡æ ‡ç‚¹åˆ†å‰²
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿ\.!?])', text)

        result = []
        current = ""

        for i in range(0, len(sentences), 2):
            sentence = sentences[i]
            # æ·»åŠ æ ‡ç‚¹
            if i + 1 < len(sentences):
                sentence += sentences[i + 1]

            result.append(sentence.strip())

        return [s for s in result if s]

    def _create_chunk(
        self,
        index: int,
        text: str,
        strategy: str,
        metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åˆ›å»ºchunkå¯¹è±¡"""
        return {
            'index': index,
            'text': text,
            'strategy': strategy,
            'metadata': metadata
        }

    def _hybrid_chunk(
        self,
        text: str,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        æ··åˆåˆ†å—ï¼ˆç»“åˆå¤šç§ç­–ç•¥ï¼‰

        ç­–ç•¥ï¼š
        1. å…ˆç”¨è¯­ä¹‰åˆ†å—è¯†åˆ«æ®µè½
        2. å¯¹è¿‡é•¿æ®µè½ä½¿ç”¨å›ºå®šå¤§å°åˆ†å—
        3. ä¿æŒç‰¹æ®Šç»“æ„å®Œæ•´
        """
        # å…ˆè¯­ä¹‰åˆ†å—
        semantic_chunks = self._semantic_chunk(text, **kwargs)

        # å¯¹è¿‡é•¿çš„å—è¿›è¡ŒäºŒæ¬¡åˆ†å—
        final_chunks = []
        chunk_index = 0

        for chunk in semantic_chunks:
            if len(chunk['text']) > 1200:
                # äºŒæ¬¡åˆ†å—
                sub_chunks = self._fixed_size_chunk(
                    chunk['text'],
                    chunk_size=600,
                    overlap=50
                )

                for sub_chunk in sub_chunks:
                    sub_chunk['index'] = chunk_index
                    sub_chunk['strategy'] = 'hybrid'
                    sub_chunk['metadata']['parent_chunk'] = chunk['index']
                    final_chunks.append(sub_chunk)
                    chunk_index += 1
            else:
                chunk['index'] = chunk_index
                chunk['strategy'] = 'hybrid'
                final_chunks.append(chunk)
                chunk_index += 1

        logger.info(f"âœ… æ··åˆåˆ†å—å®Œæˆ: {len(final_chunks)}ä¸ªå—")
        return final_chunks

    def _recursive_chunk(
        self,
        text: str,
        separators: List[str] = None,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        é€’å½’åˆ†å—ï¼ˆLangChainé£æ ¼ï¼‰

        æŒ‰ç…§åˆ†éš”ç¬¦ä¼˜å…ˆçº§é€’å½’åˆ†å‰²
        """
        if separators is None:
            separators = ['\n\n', '\n', 'ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?', ' ', '']

        chunks = []
        chunk_index = 0

        def recursive_split(text: str, separator_index: int) -> List[str]:
            """é€’å½’åˆ†å‰²å‡½æ•°"""
            if separator_index >= len(separators):
                return [text]

            separator = separators[separator_index]

            if separator:
                parts = text.split(separator)
            else:
                return [text]

            # æ£€æŸ¥æ¯éƒ¨åˆ†å¤§å°
            final_parts = []
            for part in parts:
                if len(part) <= 800:
                    final_parts.append(part)
                else:
                    # éƒ¨åˆ†å¤ªå¤§ï¼Œé€’å½’åˆ†å‰²
                    sub_parts = recursive_split(part, separator_index + 1)
                    final_parts.extend(sub_parts)

            return final_parts

        split_parts = recursive_split(text, 0)

        for part in split_parts:
            if part.strip():
                chunks.append({
                    'index': chunk_index,
                    'text': part.strip(),
                    'strategy': 'recursive',
                    'metadata': {
                        'size': len(part.strip())
                    }
                })
                chunk_index += 1

        logger.info(f"âœ… é€’å½’åˆ†å—å®Œæˆ: {len(chunks)}ä¸ªå—")
        return chunks

    def validate_chunks(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        éªŒè¯å’Œä¼˜åŒ–chunkè´¨é‡

        æ£€æŸ¥é¡¹ï¼š
        1. å—å¤§å°æ˜¯å¦åˆç†
        2. æ˜¯å¦åŒ…å«å®Œæ•´å¥å­
        3. æ˜¯å¦æœ‰è¿‡å¤šç©ºç™½
        4. ç‰¹æ®Šç»“æ„æ˜¯å¦å®Œæ•´
        """
        validated_chunks = []

        for chunk in chunks:
            text = chunk['text']

            # 1. æ£€æŸ¥å¤§å°
            if len(text) < 20:
                logger.warning(f"âš ï¸ Chunk {chunk['index']} å¤ªå°: {len(text)} å­—ç¬¦")
                continue

            if len(text) > 2000:
                logger.warning(f"âš ï¸ Chunk {chunk['index']} å¤ªå¤§: {len(text)} å­—ç¬¦")
                # å¯ä»¥é€‰æ‹©è¿›ä¸€æ­¥åˆ†å‰²æˆ–è·³è¿‡
                # è¿™é‡Œæˆ‘ä»¬ä¿ç•™ï¼Œä½†è®°å½•è­¦å‘Š

            # 2. æ£€æŸ¥ç©ºç™½æ¯”ä¾‹
            whitespace_ratio = len(re.findall(r'\s', text)) / len(text)
            if whitespace_ratio > 0.5:
                logger.warning(f"âš ï¸ Chunk {chunk['index']} ç©ºç™½æ¯”ä¾‹è¿‡é«˜: {whitespace_ratio:.2%}")

            # 3. æ£€æŸ¥å¥å­å®Œæ•´æ€§
            if not text[-1] in ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?', 'ï¼Œ', ',', ';', 'ï¼›']:
                # å¥å­å¯èƒ½ä¸å®Œæ•´ï¼Œæ ‡è®°
                chunk['metadata']['incomplete'] = True

            validated_chunks.append(chunk)

        logger.info(f"âœ… ChunkéªŒè¯å®Œæˆ: {len(validated_chunks)}/{len(chunks)} é€šè¿‡")
        return validated_chunks


def get_smart_chunking_service(
    strategy: ChunkingStrategy = ChunkingStrategy.INTELLIGENT
) -> SmartChunkingService:
    """è·å–æ™ºèƒ½åˆ†å—æœåŠ¡å®ä¾‹"""
    return SmartChunkingService(default_strategy=strategy)


__all__ = [
    'SmartChunkingService',
    'get_smart_chunking_service',
    'ChunkingStrategy'
]
