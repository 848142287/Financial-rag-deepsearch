"""
ç»Ÿä¸€ä»»åŠ¡ç®¡ç†å™¨ - æ•´åˆæ‰€æœ‰åˆ†æ•£çš„ä»»åŠ¡åŠŸèƒ½
å°†æ–‡æ¡£å¤„ç†ã€æœç´¢ã€åˆ†æç­‰åŠŸèƒ½é›†ä¸­ç®¡ç†
"""

from app.core.celery_config import celery_app
import json
from app.core.structured_logging import get_structured_logger
import asyncio
from typing import Dict, Optional
from datetime import datetime

# å¯¼å…¥ç»Ÿä¸€æœåŠ¡æ•´åˆå™¨
from app.services.core_service_integrator import get_service_integrator

# å¯¼å…¥æ•°æ®åº“ç›¸å…³
from app.core.database import SessionLocal
from app.models.document import Document

logger = get_structured_logger(__name__)

def run_async(coro):
    """è¿è¡Œå¼‚æ­¥åç¨‹çš„åŒæ­¥åŒ…è£…å™¨"""
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    return loop.run_until_complete(coro)

@celery_app.task(
    bind=True,
    soft_time_limit=1800,  # 30åˆ†é’Ÿè½¯è¶…æ—¶
    time_limit=2100,  # 35åˆ†é’Ÿç¡¬è¶…æ—¶
    max_retries=2,
    default_retry_delay=60
)
def process_document_unified(self, document_id: str, original_filename: str, user_id: str = None):
    """
    ç»Ÿä¸€çš„æ–‡æ¡£å¤„ç†ä»»åŠ¡
    æ•´åˆæ‰€æœ‰åˆ†æ•£çš„æ–‡æ¡£å¤„ç†åŠŸèƒ½ï¼Œä½¿ç”¨ç»Ÿä¸€çš„æœåŠ¡æ•´åˆå™¨

    è¶…æ—¶é…ç½®:
    - soft_time_limit: 1800ç§’ï¼ˆ30åˆ†é’Ÿï¼‰- è½¯è¶…æ—¶ï¼Œä¼šæŠ›å‡ºSoftTimeLimitExceeded
    - time_limit: 2100ç§’ï¼ˆ35åˆ†é’Ÿï¼‰- ç¡¬è¶…æ—¶ï¼Œå¼ºåˆ¶ç»ˆæ­¢ä»»åŠ¡
    - max_retries: 2 - å¤±è´¥åé‡è¯•2æ¬¡
    """
    task_id = self.request.id

    try:
        self.update_state(
            state='PROGRESS',
            meta={'status': 'åˆå§‹åŒ–æœåŠ¡', 'progress': 5}
        )

        logger.info("ğŸ“¦ ä½¿ç”¨CoreServiceIntegratorï¼ˆç¨³å®šç‰ˆï¼‰")
        integrator = get_service_integrator()
        run_async(integrator.initialize())

        self.update_state(
            state='PROGRESS',
            meta={'status': 'è·å–æ–‡æ¡£å†…å®¹', 'progress': 15}
        )

        # è·å–æ–‡æ¡£å†…å®¹
        from app.services.minio_service import MinIOService

        db = SessionLocal()
        try:
            document = db.query(Document).filter(Document.id == document_id).first()
            if not document:
                raise Exception(f"æ–‡æ¡£ä¸å­˜åœ¨: {document_id}")

            # æ›´æ–°æ–‡æ¡£çŠ¶æ€ä¸º"processing"ï¼ˆå¤„ç†ä¸­ï¼‰
            document.status = 'processing'
            document.error_message = None
            db.commit()
            logger.info(f"ğŸ“ æ–‡æ¡£ {document_id} çŠ¶æ€å·²æ›´æ–°ä¸º processing")

            # ä¸‹è½½æ–‡ä»¶å†…å®¹
            minio_service = MinIOService()

            async def get_file_content():
                # ä¿®å¤ï¼šç§»é™¤ file_path ä¸­çš„ 'documents/' å‰ç¼€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                actual_path = document.file_path
                if actual_path.startswith('documents/'):
                    actual_path = actual_path[len('documents/'):]

                content = await minio_service.download_file(actual_path)
                if content is None:
                    raise Exception(f"æ–‡ä»¶ä¸‹è½½å¤±è´¥: {document.file_path}")
                return content

            file_content = run_async(get_file_content())

        finally:
            db.close()

        self.update_state(
            state='PROGRESS',
            meta={'status': 'æ‰§è¡Œå®Œæ•´å¤„ç†æµæ°´çº¿', 'progress': 25}
        )

        # ä½¿ç”¨é€‰å®šçš„å¤„ç†å™¨å¤„ç†æ–‡æ¡£
        result = run_async(integrator.process_document(
            file_content, original_filename, document_id
        ))

        # å°†resultè½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–çš„æ ¼å¼
        def make_json_serializable(obj):
            """é€’å½’è½¬æ¢numpyæ•°ç»„å’Œå…¶ä»–ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡"""
            import numpy as np
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {k: make_json_serializable(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [make_json_serializable(item) for item in obj]
            else:
                return obj

        serializable_result = make_json_serializable(result)

        # æ›´æ–°æ•°æ®åº“
        db = SessionLocal()
        try:
            document = db.query(Document).filter(Document.id == document_id).first()
            if document:
                # æ›´æ–°å¤„ç†çŠ¶æ€å’Œç»“æœ
                document.processing_mode = "unified_pipeline"
                document.processing_result = json.dumps(serializable_result, ensure_ascii=False)

                # ä»ç»“æœä¸­æå–æ–‡æœ¬å†…å®¹
                stages = result.get('stages', {})
                if 'parsing' in stages:
                    # å°è¯•è·å–è§£æçš„æ–‡æœ¬
                    parsed_text = result.get('parsed_text', '')
                    markdown = result.get('markdown', '')
                    document.parsed_content = markdown or parsed_text or str(result)
                else:
                    document.parsed_content = str(result)

                if result.get('success'):
                    document.status = 'completed'
                    document.processed_at = datetime.now()

                    # ğŸš€ è§¦å‘åå°å¼‚æ­¥enrichmentä»»åŠ¡ï¼ˆå®ä½“æå– + çŸ¥è¯†å›¾è°±ï¼‰
                    try:
                        from app.tasks.background_enrichment import enrich_document_async

                        # è·å–chunksæ•°æ®
                        chunks_data = result.get('chunks', [])

                        # å¼‚æ­¥è§¦å‘enrichmentä»»åŠ¡ï¼Œä¸é˜»å¡ä¸»æµç¨‹
                        enrich_document_async.delay(str(document_id), chunks_data)
                        logger.info(f"âœ… å·²è§¦å‘åå°enrichmentä»»åŠ¡: {document_id}")
                    except Exception as e:
                        logger.warning(f"è§¦å‘åå°enrichmentä»»åŠ¡å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")

                else:
                    document.status = 'processing_failed'
                    document.error_message = result.get('error', 'Unknown error')

                db.commit()

        finally:
            db.close()

        self.update_state(
            state='SUCCESS',
            meta={'status': 'å¤„ç†å®Œæˆ', 'progress': 100, 'result': result}
        )

        logger.info(f"âœ… ç»Ÿä¸€æ–‡æ¡£å¤„ç†å®Œæˆ: {document_id}")
        return result

    except Exception as e:
        logger.error(f"âŒ ç»Ÿä¸€æ–‡æ¡£å¤„ç†å¤±è´¥ {document_id}: {e}")

        # æ›´æ–°é”™è¯¯çŠ¶æ€
        db = SessionLocal()
        try:
            document = db.query(Document).filter(Document.id == document_id).first()
            if document:
                document.status = 'processing_failed'
                document.error_message = str(e)
                db.commit()
        finally:
            db.close()

        # é‡è¯•é€»è¾‘
        raise self.retry(exc=e, countdown=60, max_retries=3)

@celery_app.task(bind=True)
def search_documents_unified(self, query: str, top_k: int = 10, filters: Optional[Dict] = None):
    """
    ç»Ÿä¸€çš„æ–‡æ¡£æœç´¢ä»»åŠ¡
    æ•´åˆå‘é‡æœç´¢å’ŒçŸ¥è¯†å›¾è°±æœç´¢
    """
    task_id = self.request.id

    try:
        self.update_state(
            state='PROGRESS',
            meta={'status': 'åˆå§‹åŒ–æœç´¢æœåŠ¡', 'progress': 20}
        )

        # è·å–ç»Ÿä¸€æœåŠ¡æ•´åˆå™¨
        integrator = get_service_integrator()
        run_async(integrator.initialize())

        self.update_state(
            state='PROGRESS',
            meta={'status': 'æ‰§è¡Œæœç´¢', 'progress': 60}
        )

        # æ‰§è¡Œæœç´¢
        results = run_async(integrator.search_documents(query, top_k, filters))

        self.update_state(
            state='SUCCESS',
            meta={'status': 'æœç´¢å®Œæˆ', 'progress': 100, 'result_count': len(results)}
        )

        return {
            'query': query,
            'results': results,
            'total_count': len(results),
            'task_id': task_id
        }

    except Exception as e:
        logger.error(f"âŒ ç»Ÿä¸€æœç´¢å¤±è´¥: {e}")
        raise self.retry(exc=e, countdown=30, max_retries=2)

@celery_app.task(bind=True)
def system_health_check(self):
    """
    ç³»ç»Ÿå¥åº·æ£€æŸ¥ä»»åŠ¡
    æ£€æŸ¥æ‰€æœ‰æœåŠ¡çš„çŠ¶æ€
    """
    try:
        integrator = get_service_integrator()

        # æ£€æŸ¥æœåŠ¡çŠ¶æ€
        status = run_async(integrator.get_service_status())
        config_summary = integrator.get_config_summary()

        return {
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'services': status['services'],
            'config': config_summary
        }

    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            'status': 'unhealthy',
            'timestamp': datetime.now().isoformat(),
            'error': str(e)
        }

# å‘åå…¼å®¹çš„åˆ«å
process_document_complete = process_document_unified
