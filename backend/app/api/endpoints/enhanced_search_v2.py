"""
å¢å¼ºç‰ˆæœç´¢APIç«¯ç‚¹ v2
æä¾›ç»“æ„åŒ–ç­”æ¡ˆå’Œå½’ä¸€åŒ–ç›¸ä¼¼åº¦åˆ†æ•°
"""

from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from typing import Dict, Any, List, Optional
from pydantic import BaseModel
import logging
import asyncio

from app.core.database import get_db
from app.services.smart_embedding_service import SmartEmbeddingService
from app.services.enhanced_answer_service import EnhancedAnswerService
from pymilvus import connections, Collection

logger = logging.getLogger(__name__)

router = APIRouter()


class EnhancedSearchRequest(BaseModel):
    query: str
    top_k: int = 10
    use_knowledge_graph: bool = True
    use_vector_search: bool = True
    enable_reranking: bool = True
    normalize_scores: bool = True
    user_id: Optional[str] = None


@router.post("/enhanced-search-v2")
async def enhanced_search_v2(
    request: EnhancedSearchRequest,
    db: Session = Depends(get_db)
):
    """
    å¢å¼ºç‰ˆæœç´¢æ¥å£ v2
    
    ç‰¹ç‚¹ï¼š
    1. ç»“æ„åŒ–ç­”æ¡ˆï¼ˆæ‘˜è¦ + è¦ç‚¹ + è¯¦ç»†è¯´æ˜ï¼‰
    2. å½’ä¸€åŒ–ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-1èŒƒå›´ï¼‰
    3. ç™¾åˆ†æ¯”ç›¸ä¼¼åº¦å±•ç¤º
    4. é«˜è´¨é‡LLMç­”æ¡ˆç”Ÿæˆ
    """
    try:
        logger.info(f"ğŸš€ å¢å¼ºç‰ˆæœç´¢ v2: '{request.query}'")
        
        # 1. å‘é‡æ£€ç´¢
        embedding_service = SmartEmbeddingService()
        query_embedding = await embedding_service.encode_single(request.query)
        
        # è¿æ¥Milvus
        connections.connect(host='milvus', port='19530')
        collection = Collection("document_embeddings")
        collection.load()
        
        # å‘é‡æœç´¢ï¼ˆä½¿ç”¨å†…ç§¯IPï¼‰
        search_params = {
            "metric_type": "IP",  # å†…ç§¯
            "params": {"nprobe": 10}
        }
        
        results = collection.search(
            [query_embedding],
            "embedding",
            search_params,
            limit=request.top_k,
            output_fields=["content", "document_id", "chunk_id", "metadata"]
        )
        
        # 2. å¤„ç†æœç´¢ç»“æœ
        search_results = []
        for hit in results[0]:
            search_results.append({
                "id": str(hit.entity.get("document_id", hit.id)),
                "title": hit.entity.get("metadata", {}).get("title", "æ–‡æ¡£")[:100],
                "content": hit.entity.get("content", ""),
                "score": float(hit.distance),  # å†…ç§¯åˆ†æ•°
                "chunk_id": hit.entity.get("chunk_id", ""),
                "metadata": hit.entity.get("metadata", {})
            })
        
        # 3. é‡æ’åºï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if request.enable_reranking and len(search_results) > 1:
            logger.info("ğŸ”„ åº”ç”¨é‡æ’åº...")
            content_list = [r["content"] for r in search_results]
            rerank_scores = await embedding_service.rerank(request.query, content_list)
            
            reranked_results = []
            for idx, (original_idx, score) in enumerate(rerank_scores):
                if original_idx < len(search_results):
                    result = search_results[original_idx]
                    result["score"] = score
                    reranked_results.append(result)
            
            search_results = reranked_results[:request.top_k]
        
        # 4. è®¡ç®—åˆ†æ•°ç»Ÿè®¡ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
        score_stats = {
            'min': min(r['score'] for r in search_results),
            'max': max(r['score'] for r in search_results),
            'avg': sum(r['score'] for r in search_results) / len(search_results)
        }
        
        # 5. ç”Ÿæˆç»“æ„åŒ–ç­”æ¡ˆ
        logger.info("ğŸ“ ç”Ÿæˆç»“æ„åŒ–ç­”æ¡ˆ...")
        answer_service = EnhancedAnswerService()
        structured_answer = await answer_service.generate_structured_answer(
            query=request.query,
            search_results=search_results,
            normalize_scores=request.normalize_scores,
            score_stats=score_stats
        )
        
        # 6. æ„å»ºå“åº”
        response = {
            "query": request.query,
            "answer": structured_answer,
            "retrieval_info": {
                "total_results": len(search_results),
                "vector_search_used": request.use_vector_search,
                "reranking_applied": request.enable_reranking,
                "score_normalization_enabled": request.normalize_scores,
                "score_statistics": {
                    "min": round(score_stats['min'], 2),
                    "max": round(score_stats['max'], 2),
                    "avg": round(score_stats['avg'], 2)
                }
            },
            "performance_metrics": {
                "embedding_dimension": len(query_embedding),
                "response_time_ms": 0  # å¯ä»¥æ·»åŠ å®é™…è®¡æ—¶
            }
        }
        
        logger.info(f"âœ… æœç´¢å®Œæˆ: {len(search_results)} ä¸ªç»“æœ, ç½®ä¿¡åº¦: {structured_answer.get('confidence', 0)}%")
        
        return response
    
    except Exception as e:
        logger.error(f"âŒ å¢å¼ºç‰ˆæœç´¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"æœç´¢å¤±è´¥: {str(e)}")


@router.get("/search-v2-status")
async def search_v2_status():
    """è·å–å¢å¼ºç‰ˆæœç´¢ç³»ç»ŸçŠ¶æ€"""
    try:
        return {
            "status": "healthy",
            "version": "v2.0",
            "features": {
                "structured_answer": True,
                "normalized_similarity": True,
                "llm_answer_generation": True,
                "reranking": True
            },
            "message": "å¢å¼ºç‰ˆæœç´¢ç³»ç»Ÿè¿è¡Œæ­£å¸¸"
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)
        }
