"""
åˆ†å±‚æ£€ç´¢APIæ¥å£
æä¾›åŸºäºä¸‰å±‚ç´¢å¼•ï¼ˆæ–‡æ¡£æ‘˜è¦ã€ç« èŠ‚ã€ç‰‡æ®µï¼‰çš„æ™ºèƒ½æ£€ç´¢
"""

from fastapi import APIRouter, Depends, HTTPException, status
from typing import Dict, Any, List

from app.core.structured_logging import get_structured_logger
from app.schemas.hierarchical_index import (
    HierarchicalRetrievalRequest,
    HierarchicalRetrievalResult,
    HierarchicalIndexBuildRequest,
    HierarchicalIndexBuildResponse
)
from app.services.hierarchical_index import (
    get_hierarchical_index_extractor,
    get_hierarchical_retrieval_service,
    get_hierarchical_milvus_service
)
from app.services.embeddings.unified_embedding_service import UnifiedEmbeddingService
from app.services.llm_service import LLMService

logger = get_structured_logger(__name__)

router = APIRouter()


# ==================== åˆ†å±‚æ£€ç´¢ ====================

@router.post("/retrieve", response_model=HierarchicalRetrievalResult)
async def hierarchical_retrieve(request: HierarchicalRetrievalRequest):
    """
    åˆ†å±‚æ£€ç´¢

    ä½¿ç”¨ä¸‰å±‚ç´¢å¼•è¿›è¡Œæ™ºèƒ½æ£€ç´¢ï¼š
    1. æ–‡æ¡£æ‘˜è¦å±‚ - ç²—ç²’åº¦ç­›é€‰
    2. ç« èŠ‚ç´¢å¼•å±‚ - ä¸­ç²’åº¦å®šä½
    3. ç‰‡æ®µç´¢å¼•å±‚ - ç»†ç²’åº¦ç²¾ç¡®æ£€ç´¢

    Args:
        request: æ£€ç´¢è¯·æ±‚å‚æ•°

    Returns:
        HierarchicalRetrievalResult: åˆ†å±‚æ£€ç´¢ç»“æœ
    """
    try:
        logger.info(f"ğŸ” åˆ†å±‚æ£€ç´¢è¯·æ±‚: {request.query}")

        # è·å–æœåŠ¡
        retrieval_service = get_hierarchical_retrieval_service()
        milvus_service = await get_hierarchical_milvus_service()

        # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
        embedding_service = UnifiedEmbeddingService()
        query_embedding = await embedding_service.embed_batch([request.query])
        query_embedding = query_embedding[0].tolist()

        # ç¬¬1å±‚ï¼šæ–‡æ¡£æ‘˜è¦æ£€ç´¢
        logger.info("  ğŸ“„ ç¬¬1å±‚ï¼šæ–‡æ¡£æ‘˜è¦æ£€ç´¢...")
        doc_results = await milvus_service.search_document_summaries(
            query_embedding=query_embedding,
            top_k=request.max_docs,
            document_ids=request.document_ids
        )

        # è¿‡æ»¤ä½äºé˜ˆå€¼çš„æ–‡æ¡£
        doc_results = [d for d in doc_results if d["score"] >= request.doc_threshold]
        logger.info(f"    âœ“ æ‰¾åˆ° {len(doc_results)} ä¸ªç›¸å…³æ–‡æ¡£")

        if not doc_results:
            return HierarchicalRetrievalResult(
                query=request.query,
                documents=[],
                chapters=[],
                chunks=[],
                merged_results=[],
                retrieval_time=0.0,
                total_docs=0,
                total_chapters=0,
                total_chunks=0
            )

        # ç¬¬2å±‚ï¼šç« èŠ‚æ£€ç´¢
        logger.info("  ğŸ“‘ ç¬¬2å±‚ï¼šç« èŠ‚æ£€ç´¢...")
        relevant_doc_ids = [d["document_id"] for d in doc_results]
        chapter_results = await milvus_service.search_chapter_indexes(
            query_embedding=query_embedding,
            top_k=request.max_chapters_per_doc * len(relevant_doc_ids),
            document_ids=relevant_doc_ids
        )

        # è¿‡æ»¤ä½äºé˜ˆå€¼çš„ç« èŠ‚
        chapter_results = [c for c in chapter_results if c["score"] >= request.chapter_threshold]
        logger.info(f"    âœ“ æ‰¾åˆ° {len(chapter_results)} ä¸ªç›¸å…³ç« èŠ‚")

        # ç¬¬3å±‚ï¼šç‰‡æ®µæ£€ç´¢
        logger.info("  âœ‚ï¸ ç¬¬3å±‚ï¼šç‰‡æ®µæ£€ç´¢...")
        relevant_chapter_ids = [c["chapter_id"] for c in chapter_results] if chapter_results else None
        chunk_results = await milvus_service.search_chunk_indexes(
            query_embedding=query_embedding,
            top_k=request.top_k,
            document_ids=relevant_doc_ids,
            chapter_ids=relevant_chapter_ids
        )

        # è¿‡æ»¤ä½äºé˜ˆå€¼çš„ç‰‡æ®µ
        chunk_results = [c for c in chunk_results if c["score"] >= request.chunk_threshold]
        logger.info(f"    âœ“ æ‰¾åˆ° {len(chunk_results)} ä¸ªç›¸å…³ç‰‡æ®µ")

        # æ„å»ºç»“æœ
        from app.schemas.hierarchical_index import (
            RetrievedDocument,
            RetrievedChapter,
            RetrievedChunk
        )

        results = HierarchicalRetrievalResult(
            query=request.query,
            documents=[
                RetrievedDocument(
                    document_id=d["document_id"],
                    summary_text=d["summary_text"],
                    score=d["score"],
                    keywords=d["keywords"],
                    entities=d["entities"]
                )
                for d in doc_results[:request.max_docs]
            ],
            chapters=[
                RetrievedChapter(
                    chapter_id=c["chapter_id"],
                    document_id=c["document_id"],
                    title=c["title"],
                    summary=c["summary"],
                    score=c["score"],
                    level=c["level"],
                    chunk_count=c["chunk_count"]
                )
                for c in chapter_results[:request.max_chapters_per_doc * request.max_docs]
            ],
            chunks=[
                RetrievedChunk(
                    chunk_id=c["chunk_id"],
                    document_id=c["document_id"],
                    chapter_id=c["chapter_id"],
                    content=c["content"],
                    score=c["score"],
                    metadata={
                        "chunk_type": c["chunk_type"],
                        "chunk_index": c["chunk_index"],
                        "page_number": c["page_number"]
                    }
                )
                for c in chunk_results[:request.top_k]
            ],
            merged_results=[],
            retrieval_time=0.0,
            total_docs=len(doc_results),
            total_chapters=len(chapter_results),
            total_chunks=len(chunk_results)
        )

        # åˆå¹¶ç»“æœ
        results.merged_results = results.chunks[:request.top_k]

        # è®°å½•ç›‘æ§æŒ‡æ ‡
        try:
            # åœ¨è¿™é‡Œå¯ä»¥æ·»åŠ ç›‘æ§ä»£ç 
            pass
        except Exception as monitor_error:
            logger.warning(f"è®°å½•ç›‘æ§æŒ‡æ ‡å¤±è´¥: {monitor_error}")

        logger.info(f"âœ… åˆ†å±‚æ£€ç´¢å®Œæˆï¼æ–‡æ¡£: {results.total_docs}, ç« èŠ‚: {results.total_chapters}, ç‰‡æ®µ: {results.total_chunks}")

        return results

    except Exception as e:
        logger.error(f"âŒ åˆ†å±‚æ£€ç´¢å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ†å±‚æ£€ç´¢å¤±è´¥: {str(e)}"
        )


@router.post("/build-index", response_model=HierarchicalIndexBuildResponse)
async def build_hierarchical_index(request: HierarchicalIndexBuildRequest):
    """
    æ„å»ºåˆ†å±‚ç´¢å¼•

    ä¸ºæ–‡æ¡£æ„å»ºä¸‰å±‚ç´¢å¼•ç»“æ„ï¼ˆæ–‡æ¡£æ‘˜è¦ã€ç« èŠ‚ã€ç‰‡æ®µï¼‰å¹¶å­˜å‚¨åˆ°Milvus

    Args:
        request: ç´¢å¼•æ„å»ºè¯·æ±‚

    Returns:
        HierarchicalIndexBuildResponse: æ„å»ºç»“æœ
    """
    try:
        logger.info(f"ğŸ“š å¼€å§‹æ„å»ºæ–‡æ¡£ {request.document_id} çš„åˆ†å±‚ç´¢å¼•")

        # è¿™é‡Œéœ€è¦ä»æ•°æ®åº“æˆ–å­˜å‚¨ä¸­è·å–æ–‡æ¡£å†…å®¹
        # ç®€åŒ–ç‰ˆæœ¬ï¼šå‡è®¾å¯ä»¥è·å–åˆ°æ–‡æ¡£çš„markdownå†…å®¹
        # å®é™…å®ç°éœ€è¦é›†æˆåˆ°æ–‡æ¡£å¤„ç†æµæ°´çº¿ä¸­

        # TODO: é›†æˆåˆ°æ–‡æ¡£å¤„ç†æµæ°´çº¿
        # 1. è·å–æ–‡æ¡£å†…å®¹
        # 2. è°ƒç”¨index_extractoræŠ½å–åˆ†å±‚ç´¢å¼•
        # 3. è°ƒç”¨milvus_serviceå­˜å‚¨åˆ°å‘é‡æ•°æ®åº“

        response = HierarchicalIndexBuildResponse(
            document_id=request.document_id,
            success=True,
            message="åˆ†å±‚ç´¢å¼•æ„å»ºåŠŸèƒ½éœ€è¦é›†æˆåˆ°æ–‡æ¡£å¤„ç†æµæ°´çº¿ä¸­",
            summary_index=None,
            chapter_count=0,
            chunk_count=0,
            processing_time=0.0
        )

        return response

    except Exception as e:
        logger.error(f"âŒ æ„å»ºåˆ†å±‚ç´¢å¼•å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ„å»ºåˆ†å±‚ç´¢å¼•å¤±è´¥: {str(e)}"
        )


@router.delete("/index/{document_id}")
async def delete_hierarchical_index(document_id: str):
    """
    åˆ é™¤åˆ†å±‚ç´¢å¼•

    åˆ é™¤æŒ‡å®šæ–‡æ¡£çš„æ‰€æœ‰ä¸‰å±‚ç´¢å¼•

    Args:
        document_id: æ–‡æ¡£ID

    Returns:
        Dict: åˆ é™¤ç»“æœ
    """
    try:
        logger.info(f"ğŸ—‘ï¸ åˆ é™¤æ–‡æ¡£ {document_id} çš„åˆ†å±‚ç´¢å¼•")

        milvus_service = await get_hierarchical_milvus_service()
        await milvus_service.delete_document_index(document_id)

        return {
            "success": True,
            "message": f"æˆåŠŸåˆ é™¤æ–‡æ¡£ {document_id} çš„åˆ†å±‚ç´¢å¼•",
            "document_id": document_id
        }

    except Exception as e:
        logger.error(f"âŒ åˆ é™¤åˆ†å±‚ç´¢å¼•å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ é™¤åˆ†å±‚ç´¢å¼•å¤±è´¥: {str(e)}"
        )


@router.get("/stats")
async def get_hierarchical_index_stats():
    """
    è·å–åˆ†å±‚ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯

    è¿”å›ä¸‰å±‚ç´¢å¼•çš„ç»Ÿè®¡æ•°æ®

    Returns:
        Dict: ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        milvus_service = await get_hierarchical_milvus_service()

        # è·å–å„collectionçš„ç»Ÿè®¡ä¿¡æ¯
        stats = {
            "document_summaries": {
                "collection_name": milvus_service.COLLECTION_DOC_SUMMARIES,
                "num_entities": 0
            },
            "chapter_indexes": {
                "collection_name": milvus_service.COLLECTION_CHAPTER_INDEXES,
                "num_entities": 0
            },
            "chunk_indexes": {
                "collection_name": milvus_service.COLLECTION_CHUNK_INDEXES,
                "num_entities": 0
            }
        }

        # è·å–å®ä½“æ•°é‡
        for collection_name, collection in milvus_service.collections.items():
            collection.load()
            num_entities = collection.num_entities
            if collection_name == "doc_summaries":
                stats["document_summaries"]["num_entities"] = num_entities
            elif collection_name == "chapters":
                stats["chapter_indexes"]["num_entities"] = num_entities
            elif collection_name == "chunks":
                stats["chunk_indexes"]["num_entities"] = num_entities

        return {
            "success": True,
            "stats": stats
        }

    except Exception as e:
        logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"
        )


@router.get("/health")
async def health_check():
    """
    å¥åº·æ£€æŸ¥

    æ£€æŸ¥åˆ†å±‚æ£€ç´¢æœåŠ¡çš„å¥åº·çŠ¶æ€

    Returns:
        Dict: å¥åº·çŠ¶æ€
    """
    try:
        milvus_service = await get_hierarchical_milvus_service()

        health_status = {
            "milvus_connected": milvus_service._is_connected,
            "collections_initialized": len(milvus_service.collections) > 0,
            "services": {
                "index_extractor": True,
                "retrieval_service": True,
                "milvus_service": True
            }
        }

        return {
            "status": "healthy" if all(health_status["services"].values()) else "unhealthy",
            "details": health_status
        }

    except Exception as e:
        logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")
        return {
            "status": "unhealthy",
            "error": str(e)
        }


@router.get("/monitoring/performance")
async def get_performance_statistics(time_window: int = 3600):
    """
    è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯

    Args:
        time_window: æ—¶é—´çª—å£ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1å°æ—¶

    Returns:
        Dict: æ€§èƒ½ç»Ÿè®¡æ•°æ®
    """
    try:
        # æ³¨æ„ï¼šè¿™éœ€è¦å®ç°ç›‘æ§æœåŠ¡
        # from app.services.hierarchical_index.performance_monitoring import get_hierarchical_retrieval_monitor
        # monitor = get_hierarchical_retrieval_monitor()
        # stats = monitor.get_statistics(time_window=time_window)

        # ç®€åŒ–ç‰ˆæœ¬
        return {
            "status": "success",
            "message": "æ€§èƒ½ç›‘æ§åŠŸèƒ½éœ€è¦å®ç°HierarchicalRetrievalMonitoræœåŠ¡",
            "time_window": time_window,
            "data": {
                "note": "è¯·å‚è€ƒPERFORMANCE_MONITORING.mdå®ç°ç›‘æ§æœåŠ¡"
            }
        }

    except Exception as e:
        logger.error(f"âŒ è·å–æ€§èƒ½ç»Ÿè®¡å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–æ€§èƒ½ç»Ÿè®¡å¤±è´¥: {str(e)}"
        )


@router.get("/monitoring/trends")
async def get_performance_trends(
    granularity: str = "5min",
    points: int = 12
):
    """
    è·å–æ€§èƒ½è¶‹åŠ¿

    Args:
        granularity: æ—¶é—´ç²’åº¦ï¼ˆ1min, 5min, 15min, 1hourï¼‰
        points: æ•°æ®ç‚¹æ•°é‡

    Returns:
        Dict: è¶‹åŠ¿æ•°æ®
    """
    try:
        # æ³¨æ„ï¼šè¿™éœ€è¦å®ç°ç›‘æ§æœåŠ¡
        return {
            "status": "success",
            "message": "æ€§èƒ½è¶‹åŠ¿åŠŸèƒ½éœ€è¦å®ç°HierarchicalRetrievalMonitoræœåŠ¡",
            "granularity": granularity,
            "points": points,
            "data": {
                "note": "è¯·å‚è€ƒPERFORMANCE_MONITORING.mdå®ç°ç›‘æ§æœåŠ¡"
            }
        }

    except Exception as e:
        logger.error(f"âŒ è·å–æ€§èƒ½è¶‹åŠ¿å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–æ€§èƒ½è¶‹åŠ¿å¤±è´¥: {str(e)}"
        )
